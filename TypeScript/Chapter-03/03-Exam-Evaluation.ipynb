{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2852993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css : string = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b8a55",
   "metadata": {},
   "source": [
    "# Evaluating an Exam Using Lezer\n",
    "\n",
    "This notebook shows how we can use the module [`lezer`](https://lezer.codemirror.net/docs/guide/#writing-a-grammar) to implement a scanner (and parser).\n",
    "\n",
    "Our goal is to implement a program that can be used to evaluate the results of an exam.\n",
    "\n",
    "Assume the result of an exam is stored in the string `data` that is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data: string = `Class: Algorithms and Complexity\n",
    "          Group: TINF22AI1\n",
    "          MaxPoints = 60\n",
    "   \n",
    "          Exercise:      1. 2. 3. 4. 5. 6.\n",
    "          Jim Smith:     9 12 10  6  6  0\n",
    "          John Slow:     4  4  2  0  -  -\n",
    "          Susi Sorglos:  9 12 12  9  9  6\n",
    "          1609922:       7  4 12  5  5  3\n",
    "       `;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe31985",
   "metadata": {},
   "source": [
    "This data show that there has been a exam with the subject <em style=\"color:blue\">Algorithms and Complexity</em>\n",
    "in the group <em style=\"color:blue\">TIT22AI1</em>.  Furthermore, the equation\n",
    "```\n",
    "   MaxPoints = 60\n",
    "```\n",
    "shows that in order to achieve the best mark, <em style=\"color:blue\">60</em> points would have been necessary.\n",
    "\n",
    "There have been 6 different exercises in this exam and, in this small example,  only four students took part, namely *Jim Smith*, *John Slow*, *Susi Sorglos*, and some student that is only represented by their matriculation number.  Each of the rows decribing the results of the students begins with the name (or matriculation number) of the student followed by the number of points that they have achieved in the different exercises. Our goal is to write a program that is able to compute the marks for all students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbfe9a",
   "metadata": {},
   "source": [
    "## Importing the Lezer Library\n",
    "\n",
    "We will use the package [Lezer](https://lezer.codemirror.net/).\n",
    "\n",
    "Lezer uses a declarative grammar. We need:\n",
    "\n",
    "- `buildParser` from `@lezer/generator` to compile the grammar.\n",
    "- `Tree` and `TreeCursor` from `@lezer/common` to traverse the syntax tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57828de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { buildParser } from '@lezer/generator';\n",
    "import { Tree, TreeCursor } from '@lezer/common';\n",
    "import { LRParser } from '@lezer/lr';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf119d",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfa0c0",
   "metadata": {},
   "source": [
    "The function `mark(maxPoints: number, points: number): number` takes two arguments and returns a numeric grade:\n",
    "\n",
    "**Parameters:**\n",
    "- `maxPoints: number` - The number of points needed to achieve the best mark of 1.0\n",
    "- `points: number` - The number of points achieved by the student\n",
    "\n",
    "**Return value:**\n",
    "- `number` - The calculated grade (between 1.0 and 5.0)\n",
    "\n",
    "It is assumed that the relation between the mark and the points is mostly linear. A student who achieves 50% of `maxPoints` will get the mark 4.0, while 100% results in mark 1.0.\n",
    "\n",
    "The formula to calculate the grade is:\n",
    "$$ \\textrm{grade} = 7 - 6 \\cdot \\frac{\\texttt{points}}{\\texttt{maxPoints}} $$\n",
    "\n",
    "However, the worst mark is 5.0. The `Math.min()` function ensures the grade does not exceed 5.0. The result is rounded to one decimal place using `Math.round()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a009534",
   "metadata": {},
   "outputs": [],
   "source": [
    "function mark(maxPoints: number, points: number): number {\n",
    "    if (maxPoints === 0) return 0; // Prevent division by zero\n",
    "    const grade = 7 - (6 * points) / maxPoints;\n",
    "    return Math.round(Math.min(5.0, grade) * 10) / 10;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f802f",
   "metadata": {},
   "source": [
    "## Token Extraction Logic\n",
    "\n",
    "The `Token` interface formally defines a semantic unit as a tuple $t = (\\text{type}, \\text{value})$, mapping a syntactic category to a specific substring of the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3801c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface Token {\n",
    "    type: string;\n",
    "    value: string;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d269eb",
   "metadata": {},
   "source": [
    " The `extractTokens` function linearizes the hierarchical Abstract Syntax Tree (AST) by iterating through nodes with a cursor to construct a flat sequence of these tokens. During traversal, structural non-terminals (such as \"ExamData\" or \"Header\") are filtered out based on an exclusion set $\\mathcal{F}$ to retain only atomic elements. To ensure robustness, the algorithm simultaneously normalizes parser artifacts, mapping the \"⚠\" symbol to a standard \"Error\" type via a function $\\eta$. Finally, the accumulated tokens are returned as a list $L = [t_1, \\dots, t_n]$ for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac4ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function extractTokens(tree: Tree, source: string): Token[] {\n",
    "    const cursor: TreeCursor = tree.cursor();\n",
    "    const tokens: Token[] = [];\n",
    "\n",
    "    do {\n",
    "        if (\n",
    "            [\n",
    "                \"ExamData\",\n",
    "                \"line\",\n",
    "                \"StudentRecord\",\n",
    "                \"EmptyLine\",\n",
    "                \"Header\",\n",
    "            ].includes(cursor.name)\n",
    "        ) {\n",
    "            continue;\n",
    "        }\n",
    "\n",
    "        const token: Token = {\n",
    "            type: cursor.name === \"⚠\" ? \"Error\" : cursor.name,\n",
    "            value: source.substring(cursor.from, cursor.to),\n",
    "        };\n",
    "\n",
    "        tokens.push(token);\n",
    "    } while (cursor.next());\n",
    "\n",
    "    return tokens;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b9e5b",
   "metadata": {},
   "source": [
    "## Visualizing the Grading Function\n",
    "\n",
    "To better understand how our `mark()` function converts points to grades, let's visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { plotGradeFunction } from \"./utils/plotGrade\";\n",
    "\n",
    "plotGradeFunction(mark, 60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211aca2",
   "metadata": {},
   "source": [
    "The resulting plot shows how the grade decreases linearly from 5.0 (worst) at 0 points to 1.0 (best) at 60 points, with a grade of 4.0 achieved at exactly 50% of the maximum points (30 points)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558bc6e",
   "metadata": {},
   "source": [
    "## Defining the Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34036826",
   "metadata": {},
   "source": [
    "We will define the grammar in segments, explaining the purpose of each rule before adding it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e86d21",
   "metadata": {},
   "source": [
    "### 1. Entry Point and Structure\n",
    "\n",
    "First, we define the structure of our document. The `@top` rule declares that our file (`ExamData`) consists of a sequence of lines (`line*`).\n",
    "\n",
    "A `line` can be one of several types:\n",
    "\n",
    "* A `Header` (informational text)\n",
    "* A `MaxDef` (configuration of max points)\n",
    "* A `StudentRecord` (the actual grading data)\n",
    "* An `EmptyLine`\n",
    "\n",
    "We map these structural rules to the specific tokens we will define later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "const entryPoint: string = `\n",
    "  @top ExamData { line* }\n",
    "\n",
    "  line {\n",
    "    Header |\n",
    "    MaxDef |\n",
    "    StudentRecord |\n",
    "    EmptyLine\n",
    "  }\n",
    "\n",
    "  // Structure Mapping\n",
    "  Header { header }\n",
    "  MaxDef { maxdef }\n",
    "  StudentRecord { (Name | Matriculation) Number* Linebreak }\n",
    "  EmptyLine { Linebreak }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b1a7e",
   "metadata": {},
   "source": [
    "### 2. Token Block Start\n",
    "We begin the `@tokens` block, where we define the lexical patterns (Regular Expressions) for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "const tokenStart: string = `\n",
    "  @tokens {\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaeb93",
   "metadata": {},
   "source": [
    "### 3. Informational Headers\n",
    "\n",
    "The `header` token matches lines like `Class: ...` or `Group: ...`.\n",
    "The pattern `$[A-Za-z]+ \":\" ![\\n]* \"\\n\"` matches:\n",
    "\n",
    "1. One or more letters.\n",
    "2. A colon.\n",
    "3. Any content that is *not* a newline.\n",
    "4. The newline character itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88051be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "const headerTokens: string = `\n",
    "    header { $[A-Za-z]+ \":\" ![\\\\n]* \"\\\\n\" }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95890d5",
   "metadata": {},
   "source": [
    "### 4. Configuration (MaxPoints)\n",
    "The `maxdef` token extracts the maximum points definition.\n",
    "The pattern matches the literal \"MaxPoints\", optional whitespace, an equals sign, and a number (defined as a non-zero digit followed by any digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0446d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const configTokens: string = `\n",
    "    maxdef { \"MaxPoints\" $[ \\\\t]* \"=\" $[ \\\\t]* $[1-9] $[0-9]* }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610410c5",
   "metadata": {},
   "source": [
    "### 5. Student Identifiers\n",
    "\n",
    "We need to identify students either by name or matriculation number.\n",
    "\n",
    "* `Name`: Matches sequences of letters separated by spaces, ending with a colon (e.g., \"Jim Smith:\").\n",
    "* `Matriculation`: Matches exactly 7 digits followed by a colon (e.g., \"1609922:\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63245e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "const identityTokens: string = `\n",
    "    Name { $[A-Za-z]+ (\" \" $[A-Za-z]+)+ \":\" }\n",
    "    Matriculation { $[0-9] $[0-9] $[0-9] $[0-9] $[0-9] $[0-9] $[0-9] \":\" }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a38c4",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Scores and Values\n",
    "\n",
    "For the points, we define:\n",
    "\n",
    "* `Number`: Either \"0\" or a number starting with 1-9 (preventing leading zeros like \"01\").\n",
    "* `Dash`: A single `-`, representing a skipped exercise.\n",
    "* `Linebreak`: Specifically captures `\\n` to signal the end of a student record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const valueTokens: string = `\n",
    "    Number { \"0\" | $[1-9] $[0-9]* }\n",
    "    Dash { \"-\" }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a72124",
   "metadata": {},
   "source": [
    "### 7. Whitespace and Skipping\n",
    "\n",
    "Finally, we define whitespace (`space`) as spaces, tabs, or carriage returns.\n",
    "We close the `@tokens` block and define a `@skip` block. This tells the parser to automatically ignore `space` and `Dash` tokens, so we only process meaningful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "const skipAndClose: string = `\n",
    "    Linebreak { \"\\\\n\" }\n",
    "    space { $[ \\\\t\\\\r]+ }\n",
    "  }\n",
    "\n",
    "  @skip { space | Dash }\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5835b9",
   "metadata": {},
   "source": [
    "### Building the Final Grammar\n",
    "\n",
    "We concatenate all the parts to form the complete grammar string and build the parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "const finalGrammar: string =\n",
    "    entryPoint +\n",
    "    tokenStart +\n",
    "    headerTokens +\n",
    "    configTokens +\n",
    "    identityTokens +\n",
    "    valueTokens +\n",
    "    skipAndClose;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99027949",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalGrammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const parser: LRParser = buildParser(finalGrammar);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572233e",
   "metadata": {},
   "source": [
    "## Processing the Exam Data\n",
    "\n",
    "Now we implement the logic to process the token stream. We iterate over the tokens extracted from the tree and update our state machine accordingly.\n",
    "\n",
    "* **`maxdef`**: Updates the maximum possible points.\n",
    "* **`Name` / `Matriculation`**: Resets the point counter and sets the current student name.\n",
    "* **`Number`**: Adds to the current student's point total.\n",
    "* **`Linebreak`**: Triggers the calculation and output of the grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f1bb7",
   "metadata": {},
   "source": [
    "### Step 1: Numeric Value Extraction\n",
    "\n",
    "The `extractMaxPoints` function accepts a raw string literal $S$ (e.g., `\"max_points: 60\"`) and isolates the quantitative value embedded within it. It utilizes the regular expression $R = [1-9][0-9]*$ to scan $S$ for the first sequence of digits representing a positive integer, ignoring structural text. Upon finding a match, the substring is parsed into a decimal integer $N \\in \\mathbb{Z}$; otherwise, a default value of $0$ is returned to ensure type safety. This process transforms semi-structured configuration tokens into computable numeric limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7279c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function extractMaxPoints(tokenImage: string): number {\n",
    "    const match = tokenImage.match(/[1-9][0-9]*/);\n",
    "    return match ? parseInt(match[0]) : 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfc615",
   "metadata": {},
   "source": [
    "### Step 2: Starting a New Student Record\n",
    "\n",
    "The `startNewStudent` function acts as a pre-processor for identifier tokens, taking an input string $S$ that technically acts as a syntactic delimiter (e.g., `\"Name:\"`). Since the token includes a trailing colon used by the parser to recognize the record start, this character must be removed to retrieve the actual data value. The function performs a slicing operation to return the substring $S' = S[0, \\dots, |S|-2]$, effectively truncating the last character. This yields the clean student identifier string required to initialize a new data record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function startNewStudent(tokenImage: string): string {\n",
    "    return tokenImage.slice(0, -1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ffccc",
   "metadata": {},
   "source": [
    "### Step 3: Outputting a Student's Grade\n",
    "\n",
    "The `outputGrade` function executes the terminal operation for a student record by accepting the identifier $Id$, the accumulated total $P_{total}$, and the reference maximum $P_{max}$. It delegates the algorithmic evaluation to the auxiliary `mark` function, which computes the final classification $G = f(P_{total}, P_{max})$. The function then interpolates these values into a structured format string to provide human-readable feedback. Finally, this synthesized result is emitted to the standard output stream, effectively closing the processing cycle for the current entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b88d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function outputGrade(\n",
    "    name: string,\n",
    "    totalPoints: number,\n",
    "    maxPoints: number,\n",
    "): void {\n",
    "    const grade = mark(maxPoints, totalPoints);\n",
    "    console.log(\n",
    "        `${name} has ${totalPoints} points and achieved the mark ${grade}.`,\n",
    "    );\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16f31e",
   "metadata": {},
   "source": [
    "### Step 4: Processing State\n",
    "\n",
    "The `ProcessingState` interface defines the mutable context required to maintain data continuity while traversing the linear token stream. It encapsulates the global constraint $P_{max}$ (`maxPoints`) alongside transient variables specific to the active record. The `currentName` acts as a temporary identifier for the student currently under analysis, while `sumPoints` serves as a running accumulator $\\Sigma p_i$ to aggregate individual sub-scores. This data structure allows the parser to persist state across disjoint tokens, ensuring that distributed data points are correctly unified into a coherent semantic object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0197a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface ProcessingState {\n",
    "    maxPoints: number;\n",
    "    currentName: string;\n",
    "    sumPoints: number;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40184c21",
   "metadata": {},
   "source": [
    "### Step 5: The Main Processing Loop\n",
    "\n",
    "The `processExamData` function acts as the central interpreter for the system, responsible for orchestrating the transition from raw text to semantic output. The pipeline begins with a **Syntactic Analysis Phase**, where the input string $S$ is parsed into an Abstract Syntax Tree (AST); this is immediately wrapped in error-handling logic to ensure the system terminates gracefully if $S \\notin \\mathcal{L}_{valid}$ (i.e., if the input is syntactically invalid). Following successful verification, the tree is linearized into a token stream $T = [t_1, t_2, \\dots, t_n]$ to facilitate sequential processing.\n",
    "\n",
    "To handle the dependencies between disjoint tokens, the function initializes a mutable state vector $\\sigma$:\n",
    "\n",
    "$$\n",
    "\\sigma = (P_{max}, \\text{ID}_{curr}, \\Sigma_{pts})\n",
    "$$\n",
    "\n",
    "Here, $P_{max}$ represents the global maximum score, $\\text{ID}_{curr}$ tracks the active student identifier, and $\\Sigma_{pts}$ serves as the running accumulator for the current record. The function then iterates through $T$, behaving as a **Finite State Machine** where specific token types trigger distinct transitions:\n",
    "\n",
    "1.  **Global Configuration:** A `MaxDef` token updates the global constraint $P_{max}$.\n",
    "2.  **Context Initialization:** `Name` or `Matriculation` tokens signal the start of a new entity, resetting the accumulator $\\Sigma_{pts} \\to 0$.\n",
    "3.  **Aggregation:** `Number` tokens trigger an additive update to the state: $\\Sigma_{pts} \\leftarrow \\Sigma_{pts} + \\text{value}$.\n",
    "4.  **Termination & Output:** A `Linebreak` token acts as a record delimiter. If a valid context exists ($\\text{ID}_{curr} \\neq \\emptyset$), the system triggers the `outputGrade` function to emit the calculated result and subsequently clears the buffer.\n",
    "\n",
    "Finally, to prevent data loss, a post-execution check runs after the loop to capture any \"orphaned\" record that may exist at the very end of the stream without a trailing newline delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ca377",
   "metadata": {},
   "outputs": [],
   "source": [
    "function processExamData(input: string): void {\n",
    "    let tree: Tree;\n",
    "    try {\n",
    "        tree = parser.parse(input);\n",
    "    } catch (e) {\n",
    "        console.error(\"Parsing failed\", e);\n",
    "        return;\n",
    "    }\n",
    "    const tokens: Token[] = extractTokens(tree, input);\n",
    "    const state: ProcessingState = {\n",
    "        maxPoints: 0,\n",
    "        currentName: \"\",\n",
    "        sumPoints: 0,\n",
    "    };\n",
    "    for (const token of tokens) {\n",
    "        switch (token.type) {\n",
    "            case \"maxdef\":\n",
    "            case \"MaxDef\":\n",
    "                state.maxPoints = extractMaxPoints(token.value);\n",
    "                break;\n",
    "            case \"Name\":\n",
    "            case \"Matriculation\":\n",
    "                if (state.currentName !== \"\") {\n",
    "                    state.currentName = \"\";\n",
    "                    state.sumPoints = 0;\n",
    "                }\n",
    "                state.currentName = startNewStudent(token.value);\n",
    "                state.sumPoints = 0;\n",
    "                break;\n",
    "            case \"Number\":\n",
    "                state.sumPoints += parseInt(token.value, 10);\n",
    "                break;\n",
    "            case \"Linebreak\":\n",
    "                if (state.currentName !== \"\") {\n",
    "                    outputGrade(\n",
    "                        state.currentName,\n",
    "                        state.sumPoints,\n",
    "                        state.maxPoints,\n",
    "                    );\n",
    "                    state.currentName = \"\";\n",
    "                }\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "    if (state.currentName !== \"\")\n",
    "        outputGrade(state.currentName, state.sumPoints, state.maxPoints);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e6a7a",
   "metadata": {},
   "source": [
    "Now let's run our scanner on the exam data and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcc7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processExamData(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe95dd",
   "metadata": {},
   "source": [
    "### How It Works: Example Trace\n",
    "\n",
    "Let's trace through what happens for one student when the loop processes the tokens:\n",
    "\n",
    "\n",
    "| Matched Token Type | Token Image | Action / Helper Function | State Update | Output |\n",
    "| :-- | :-- | :-- | :-- | :-- |\n",
    "| `Name` | `\"Jim Smith:\"` | `startNewStudent()` | `currentName = \"Jim Smith\"`, `sumPoints = 0` | |\n",
    "| `Number` | `\"9\"` | `state.sumPoints += ...` | `sumPoints = 9` | |\n",
    "| `Number` | `\"12\"` | `state.sumPoints += ...` | `sumPoints = 21` | |\n",
    "| `Number` | `\"10\"` | `state.sumPoints += ...` | `sumPoints = 31` | |\n",
    "| `Number` | `\"6\"` | `state.sumPoints += ...` | `sumPoints = 37` | |\n",
    "| `Number` | `\"6\"` | `state.sumPoints += ...` | `sumPoints = 43` | |\n",
    "| `Number` | `\"0\"` | `state.sumPoints += ...` | `sumPoints = 43` | |\n",
    "| `Linebreak` | `\"\\n\"` | `outputGrade()`, `state.currentName = ''` | `currentName = \"\"` | `\"Jim Smith has 43 points...\"` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efa4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
