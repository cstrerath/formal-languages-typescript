{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2852993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css : string = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b8a55",
   "metadata": {},
   "source": [
    "# Evaluating an Exam Using Chevrotain\n",
    "\n",
    "This notebook shows how we can use the module [`chevrotain`](https://chevrotain.io/docs/) to implement a scanner.\n",
    "\n",
    "Our goal is to implement a program that can be used to evaluate the results of an exam.\n",
    "\n",
    "Assume the result of an exam is stored in the string `data` that is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data : string = `Class: Algorithms and Complexity\n",
    "          Group: TINF22AI1\n",
    "          MaxPoints = 60\n",
    "   \n",
    "          Exercise:      1. 2. 3. 4. 5. 6.\n",
    "          Jim Smith:     9 12 10  6  6  0\n",
    "          John Slow:     4  4  2  0  -  -\n",
    "          Susi Sorglos:  9 12 12  9  9  6\n",
    "          1609922:       7  4 12  5  5  3\n",
    "       `;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe31985",
   "metadata": {},
   "source": [
    "This data show that there has been a exam with the subject <em style=\"color:blue\">Algorithms and Complexity</em>\n",
    "in the group <em style=\"color:blue\">TIT22AI1</em>.  Furthermore, the equation\n",
    "```\n",
    "   MaxPoints = 60\n",
    "```\n",
    "shows that in order to achieve the best mark, <em style=\"color:blue\">60</em> points would have been necessary.\n",
    "\n",
    "There have been 6 different exercises in this exam and, in this small example,  only four students took part, namely *Jim Smith*, *John Slow*, *Susi Sorglos*, and some student that is only represented by their matriculation number.  Each of the rows decribing the results of the students begins with the name (or matriculation number) of the student followed by the number of points that they have achieved in the different exercises. Our goal is to write a program that is able to compute the marks for all students."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbfe9a",
   "metadata": {},
   "source": [
    "## Importing the Chevrotain Library\n",
    "\n",
    "We will use the package [Chevrotain](https://chevrotain.io/).\n",
    "\n",
    "In particular, we will use:\n",
    "- The **lexer generator** provided by `createToken` and the `Lexer` class\n",
    "- **TypeScript interfaces** for type-safe token processing: `ILexingResult`, `IToken`, and `ILexingError`\n",
    "- TypeScript's built-in **regular expressions** to match and extract patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57828de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  createToken,\n",
    "  Lexer,\n",
    "  tokenMatcher,\n",
    "  TokenType,\n",
    "  ILexingResult,\n",
    "  IToken,\n",
    "  ILexingError\n",
    "} from \"chevrotain\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c0c45",
   "metadata": {},
   "source": [
    "**Interface Overview:**\n",
    "\n",
    "- `ILexingResult`: Return type of `lexer.tokenize()` containing:\n",
    "  - `tokens: IToken[]` – Array of recognized tokens\n",
    "  - `errors: ILexingError[]` – Array of lexing errors\n",
    "  - `groups: Record<string, IToken[]>` – Grouped tokens (optional)\n",
    "\n",
    "- `IToken`: Represents a single token with properties:\n",
    "  - `image: string` – The matched text\n",
    "  - `tokenType: TokenType` – The token type\n",
    "  - `startLine: number`, `startColumn: number` – Position in input\n",
    "\n",
    "- `ILexingError`: Describes lexing errors with:\n",
    "  - `line: number`, `column: number` – Error position\n",
    "  - `offset: number` – Character offset in input string\n",
    "  - `length: number` – Length of the erroneous character sequence\n",
    "  - `message: string` – Error description\n",
    "\n",
    "These interfaces enable **type-safe processing** of lexer results in TypeScript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf119d",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dfa0c0",
   "metadata": {},
   "source": [
    "The function `mark(maxPoints: number, points: number): number` takes two arguments and returns a numeric grade:\n",
    "\n",
    "**Parameters:**\n",
    "- `maxPoints: number` - The number of points needed to achieve the best mark of 1.0\n",
    "- `points: number` - The number of points achieved by the student\n",
    "\n",
    "**Return value:**\n",
    "- `number` - The calculated grade (between 1.0 and 5.0)\n",
    "\n",
    "It is assumed that the relation between the mark and the points is mostly linear. A student who achieves 50% of `maxPoints` will get the mark 4.0, while 100% results in mark 1.0.\n",
    "\n",
    "The formula to calculate the grade is:\n",
    "$$ \\textrm{grade} = 7 - 6 \\cdot \\frac{\\texttt{points}}{\\texttt{maxPoints}} $$\n",
    "\n",
    "However, the worst mark is 5.0. The `Math.min()` function ensures the grade does not exceed 5.0. The result is rounded to one decimal place using `Math.round()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a009534",
   "metadata": {},
   "outputs": [],
   "source": [
    "function mark(maxPoints: number, points: number): number {\n",
    "    const grade = 7 - 6 * points / maxPoints;\n",
    "    return Math.round(Math.min(5.0, grade) * 10) / 10;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b9e5b",
   "metadata": {},
   "source": [
    "## Visualizing the Grading Function\n",
    "\n",
    "To better understand how our `mark()` function converts points to grades, let's visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { plotGradeFunction } from \"./utils/plotGrade\";\n",
    "\n",
    "plotGradeFunction(mark, 60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e211aca2",
   "metadata": {},
   "source": [
    "The resulting plot shows how the grade decreases linearly from 5.0 (worst) at 0 points to 1.0 (best) at 60 points, with a grade of 4.0 achieved at exactly 50% of the maximum points (30 points)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1558bc6e",
   "metadata": {},
   "source": [
    "## Token Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34036826",
   "metadata": {},
   "source": [
    "In this section, we will define the tokens needed to process our exam data.\n",
    "\n",
    "Each token is created using Chevrotain's `createToken` function, which takes two main parameters:\n",
    "- `name` - A string identifying the token type\n",
    "- `pattern` - A regular expression that defines what strings this token matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e86d21",
   "metadata": {},
   "source": [
    "### The `HEADER` Token\n",
    "\n",
    "The `HEADER` token is designed to match informational lines at the beginning of our exam data.\n",
    "\n",
    "Looking at our example data:\n",
    "\n",
    "```\n",
    "Class: Algorithms and Complexity\n",
    "Group: TINF22AI1\n",
    "Exercise: 1. 2. 3. 4. 5. 6.\n",
    "```\n",
    "\n",
    "Each HEADER line follows this pattern:\n",
    "1. It starts with one or more letters (for example, \"Class\", \"Group\", or \"Exercise\")\n",
    "2. This is followed by a colon `:`\n",
    "3. After the colon comes any descriptive text (such as the course name, group, or exercise numbers)\n",
    "4. The line ends with a newline character\n",
    "\n",
    "The regular expression `/[A-Za-z]+:.*\\n/` captures this pattern:\n",
    "- `[A-Za-z]+` matches one or more letters (upper or lowercase)\n",
    "- `:` matches the literal colon character\n",
    "- `.*` matches any characters after the colon (the descriptive text)\n",
    "- `\\n` matches the newline at the end\n",
    "\n",
    "**Note:** By including the newline in the pattern, we ensure that the entire line is recognized as a single token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Header : TokenType = createToken({ \n",
    "  name: \"HEADER\", \n",
    "  pattern: /[A-Za-z]+:.*\\n/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b1a7e",
   "metadata": {},
   "source": [
    "### The `MAXDEF` Token\n",
    "\n",
    "The `MAXDEF` token matches the line that defines the maximum number of points for the exam.\n",
    "\n",
    "In our example data, this line looks like:\n",
    "\n",
    "```\n",
    "MaxPoints = 60\n",
    "```\n",
    "\n",
    "The regular expression `/MaxPoints\\s*=\\s*[1-9][0-9]*/` captures this pattern:\n",
    "- `MaxPoints` matches the literal string\n",
    "- `\\s*` matches any amount of whitespace before and after the equals sign\n",
    "- `=` matches the literal equals sign\n",
    "- `[1-9][0-9]*` matches a number without leading zeros (e.g., \"60\", \"100\")\n",
    "\n",
    "This token is important because it tells us how many points are needed for the best possible grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759acf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "const MaxDef : TokenType = createToken({ \n",
    "  name: \"MAXDEF\", \n",
    "  pattern: /MaxPoints\\s*=\\s*[1-9][0-9]*/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eaeb93",
   "metadata": {},
   "source": [
    "### The `NAME` Token\n",
    "\n",
    "The `NAME` token matches the name of a student, which is always followed by a colon.\n",
    "\n",
    "Student names can contain letters, spaces, and hyphens. For example:\n",
    "\n",
    "```\n",
    "Jim Smith:\n",
    "Susi Sorglos:\n",
    "```\n",
    "\n",
    "The regular expression `/[A-Za-z]+(?: [A-Za-z]+)+:/` ensures:\n",
    "- The name starts with one or more letters\n",
    "- It contains at least one space (to distinguish names from headers)\n",
    "- It ends with a colon `:`\n",
    "\n",
    "This token helps us identify which student the following points belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88051be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Name : TokenType = createToken({ \n",
    "  name: \"NAME\", \n",
    "  pattern: /[A-Za-z]+(?: [A-Za-z]+)+:/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95890d5",
   "metadata": {},
   "source": [
    "### The `MATRICULATION` Token\n",
    "\n",
    "The `MATRICULATION` token matches a student identification number.\n",
    "\n",
    "Some students are identified by a 7-digit matriculation number followed by a colon, for example:\n",
    "\n",
    "```\n",
    "1609922:\n",
    "```\n",
    "\n",
    "The regular expression `/[0-9]{7}:/` ensures:\n",
    "- Exactly seven digits (`[0-9]{7}`)\n",
    "- Followed by a colon (`:`)\n",
    "\n",
    "This token helps us process students who are listed by their ID instead of their name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0446d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Matriculation : TokenType = createToken({ \n",
    "  name: \"MATRICULATION\", \n",
    "  pattern: /[0-9]{7}:/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610410c5",
   "metadata": {},
   "source": [
    "### The `NUMBER` Token\n",
    "\n",
    "The `NUMBER` token matches the points a student achieved in an exercise.\n",
    "\n",
    "A number is either exactly `0` or starts with a digit from 1-9 followed by any number of digits. This prevents leading zeros, so \"007\" would be tokenized as three separate numbers: `0`, `0`, `7`.\n",
    "\n",
    "The regular expression `/0|[1-9][0-9]*/` ensures:\n",
    "- Either a single zero (`0`)\n",
    "- Or a non-zero digit followed by more digits (`[1-9][0-9]*`)\n",
    "\n",
    "These tokens are used to sum up the points for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63245e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Number : TokenType = createToken({ \n",
    "  name: \"NUMBER\", \n",
    "  pattern: /0|[1-9][0-9]*/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a38c4",
   "metadata": {},
   "source": [
    "### The `DASH` Token\n",
    "\n",
    "The `DASH` token matches a hyphen/minus character `-`.\n",
    "\n",
    "In the exam data, dashes indicate that a student did not attempt a specific exercise. For example:\n",
    "\n",
    "```\n",
    "John Slow: 4 4 2 0 - -\n",
    "```\n",
    "\n",
    "\n",
    "Here, John Slow didn't attempt exercises 5 and 6 (indicated by the dashes).\n",
    "\n",
    "The regular expression `/-/` simply matches a single dash character.\n",
    "\n",
    "Since dashes don't contribute to the point total, we add this token to the `SKIPPED` group. This means:\n",
    "- The lexer recognizes dashes (so they don't cause errors)\n",
    "- They are not included in the token stream\n",
    "- They effectively represent 0 points\n",
    "\n",
    "This is similar to how we handle whitespace - recognized but not processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Dash : TokenType = createToken({ \n",
    "  name: \"DASH\", \n",
    "  pattern: /-/, \n",
    "  group: Lexer.SKIPPED \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a72124",
   "metadata": {},
   "source": [
    "### The `IGNORE` Token\n",
    "\n",
    "Lines that contain only whitespace (spaces or tabs) should be ignored.\n",
    "\n",
    "In Chevrotain, we use a token in the `SKIPPED` group to recognize and discard these lines. The regular expression `/[ \\t\\r]+/` matches any sequence of spaces, tabs, or carriage returns.\n",
    "\n",
    "This ensures that empty lines in the input do not affect the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Whitespace : TokenType = createToken({ \n",
    "  name: \"WS\", \n",
    "  pattern: /[ \\t\\r]+/, \n",
    "  group: Lexer.SKIPPED \n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5835b9",
   "metadata": {},
   "source": [
    "### The `LINEBREAK` Token\n",
    "\n",
    "The `LINEBREAK` token matches the newline character `\\n`.\n",
    "\n",
    "This token is important for detecting the end of a student's record. When we reach a LINEBREAK, we know it's time to calculate and output the student's grade.\n",
    "\n",
    "The regular expression `/\\n/` matches a single newline character.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9f6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Linebreak : TokenType = createToken({ \n",
    "  name: \"LINEBREAK\", \n",
    "  pattern: /\\n/ \n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f93a2be",
   "metadata": {},
   "source": [
    "## Creating the Lexer\n",
    "\n",
    "Now that we have defined all our tokens, we need to collect them in an array and create the lexer.\n",
    "\n",
    "**Important:** The order of tokens matters! More specific patterns must come before more general ones to avoid ambiguity:\n",
    "- `MAXDEF` comes before `HEADER` (both contain letters and colons, but MAXDEF is more specific)\n",
    "- `MATRICULATION` comes before `NUMBER` (matriculation numbers are specific 7-digit sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "const allTokens : TokenType[] = [\n",
    "  Whitespace,\n",
    "  Dash,\n",
    "  MaxDef,\n",
    "  Header,\n",
    "  Matriculation,\n",
    "  Name,\n",
    "  Number,\n",
    "  Linebreak\n",
    "];\n",
    "\n",
    "const lexer : Lexer = new Lexer(allTokens, { positionTracking: \"full\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572233e",
   "metadata": {},
   "source": [
    "## Processing the Exam Data\n",
    "\n",
    "In Chevrotain, token recognition (lexing) and data processing are separate concerns. After tokenization, we process the token stream step-by-step.\n",
    "\n",
    "We'll build our processor from small, focused functions that each handle one responsibility.\n",
    "\n",
    "### Step 1: Extracting Maximum Points\n",
    "\n",
    "When we encounter a `MAXDEF` token (e.g., `\"max_points: 60\"`), we need to extract the number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7279c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function extractMaxPoints(tokenImage: string): number {\n",
    "  const match = tokenImage.match(/[1-9][0-9]*/);\n",
    "  return match ? parseInt(match[0]) : 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bfc615",
   "metadata": {},
   "source": [
    "This function uses a regex to find the numeric value and returns it as an integer.\n",
    "\n",
    "### Step 2: Starting a New Student Record\n",
    "\n",
    "When we see a `NAME` or `MATRICULATION` token, we begin tracking a new student:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function startNewStudent(tokenImage: string): string {\n",
    "  return tokenImage.slice(0, -1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ffccc",
   "metadata": {},
   "source": [
    "We simply remove the trailing colon (`:`) from the token to get the clean name or ID.\n",
    "\n",
    "### Step 3: Outputting a Student's Grade\n",
    "\n",
    "When we reach a `LINEBREAK`, we calculate and display the student's grade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b88d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function outputGrade(name: string, totalPoints: number, maxPoints: number): void {\n",
    "  const grade = mark(maxPoints, totalPoints);\n",
    "  console.log(`${name} has ${totalPoints} points and achieved the mark ${grade}.`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16f31e",
   "metadata": {},
   "source": [
    "This function uses our previously defined `mark()` function to calculate the grade and formats the output message.\n",
    "\n",
    "### Step 4: Processing State\n",
    "\n",
    "To track our progress through the input, we maintain a state object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0197a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface ProcessingState {\n",
    "  maxPoints: number;\n",
    "  currentName: string;\n",
    "  sumPoints: number;\n",
    "}\n",
    "\n",
    "function createInitialState(): ProcessingState {\n",
    "  return {\n",
    "    maxPoints: 0,\n",
    "    currentName: '',\n",
    "    sumPoints: 0\n",
    "  };\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df47f7d",
   "metadata": {},
   "source": [
    "The state keeps track of:\n",
    "- **`maxPoints`**: The maximum achievable points (from `MAXDEF`)\n",
    "- **`currentName`**: The student currently being processed\n",
    "- **`sumPoints`**: Running total of points for the current student\n",
    "\n",
    "### Step 5: Enhanced Error Checking\n",
    "\n",
    "The error reporting should display the **exact faulty character(s)** and their **position** in the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function printLexerErrors(input: string, errors: ILexingError[]): void {\n",
    "  for (const err of errors) {\n",
    "    const faultyText = input.substr(err.offset, err.length);\n",
    "    console.error(\n",
    "      `Lexing Error: \"${faultyText}\" at line ${err.line}, column ${err.column} (length: ${err.length}). Details: ${err.message}`\n",
    "    );\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40184c21",
   "metadata": {},
   "source": [
    "This provides users with precise feedback about **which characters caused the error** and **where they are located**, significantly improving debugging.\n",
    "\n",
    "### Step 6: The Main Processing Loop\n",
    "\n",
    "Now we can assemble our processing function from these building blocks:\n",
    "\n",
    "1. **Tokenize** the input\n",
    "2. **Check for errors** and exit if any are found\n",
    "3. **Initialize state** to track processing progress\n",
    "4. **Iterate through tokens**, calling the appropriate helper function for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ca377",
   "metadata": {},
   "outputs": [],
   "source": [
    "function processExamData(input: string): void {\n",
    "  const lexingResult: ILexingResult = lexer.tokenize(input);\n",
    "\n",
    "  if (lexingResult.errors.length > 0) {\n",
    "    printLexerErrors(input, lexingResult.errors);\n",
    "    return;\n",
    "  }\n",
    "\n",
    "  const state: ProcessingState = createInitialState();\n",
    "\n",
    "  for (const token of lexingResult.tokens) {\n",
    "    \n",
    "    if (tokenMatcher(token, MaxDef)) {\n",
    "        state.maxPoints = extractMaxPoints(token.image);\n",
    "    }\n",
    "    else if (tokenMatcher(token, Name) || tokenMatcher(token, Matriculation)) {\n",
    "        state.currentName = startNewStudent(token.image);\n",
    "        state.sumPoints = 0;\n",
    "    }\n",
    "    else if (tokenMatcher(token, Number)) {\n",
    "        const points: number = parseInt(token.image, 10);\n",
    "        state.sumPoints += points;\n",
    "    }\n",
    "    else if (tokenMatcher(token, Linebreak)) {\n",
    "        if (state.currentName !== '') {\n",
    "          outputGrade(state.currentName, state.sumPoints, state.maxPoints);\n",
    "          state.currentName = '';\n",
    "        }\n",
    "    }\n",
    "    else if (tokenMatcher(token, Header)) {\n",
    "        // Headers are recognized but don't affect processing\n",
    "    }\n",
    "    else {\n",
    "        // Optional: Handle unexpeted, since our lexer is exhaustive for valid input, this shall not be reached\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e6a7a",
   "metadata": {},
   "source": [
    "Now let's run our scanner on the exam data and see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcc7b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processExamData(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe95dd",
   "metadata": {},
   "source": [
    "### How It Works: Example Trace\n",
    "\n",
    "Let's trace through what happens for one student when the loop processes the tokens:\n",
    "\n",
    "\n",
    "| Matched Token Type | Token Image | Action / Helper Function | State Update | Output |\n",
    "| :-- | :-- | :-- | :-- | :-- |\n",
    "| `Name` | `\"Jim Smith:\"` | `startNewStudent()` | `currentName = \"Jim Smith\"`, `sumPoints = 0` | |\n",
    "| `Number` | `\"9\"` | `state.sumPoints += ...` | `sumPoints = 9` | |\n",
    "| `Number` | `\"12\"` | `state.sumPoints += ...` | `sumPoints = 21` | |\n",
    "| `Number` | `\"10\"` | `state.sumPoints += ...` | `sumPoints = 31` | |\n",
    "| `Number` | `\"6\"` | `state.sumPoints += ...` | `sumPoints = 37` | |\n",
    "| `Number` | `\"6\"` | `state.sumPoints += ...` | `sumPoints = 43` | |\n",
    "| `Number` | `\"0\"` | `state.sumPoints += ...` | `sumPoints = 43` | |\n",
    "| `Linebreak` | `\"\\n\"` | `outputGrade()`, `state.currentName = ''` | `currentName = \"\"` | `\"Jim Smith has 43 points...\"` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efa4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
