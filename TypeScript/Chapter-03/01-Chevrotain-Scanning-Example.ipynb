{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d894ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style><link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\n",
       "<link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\n",
       "\n",
       "<style>\n",
       "\n",
       "@font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       ".container { width: 100% }\n",
       "\n",
       "/* Formatting for header cells */\n",
       ".text_cell_render h1 {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 2.2em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(0, 80, 120);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       ".text_cell_render h2 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    font-weight: 400;\n",
       "    font-size: 1.9em;\n",
       "    line-height: 100%;\n",
       "    color: rgb(200,100,0);\n",
       "    margin-bottom: 0.1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\t\n",
       "\n",
       ".text_cell_render h3 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "    font-style: italic;\n",
       "    color: rgb(94,127,192);\n",
       "}\n",
       "\n",
       ".text_cell_render h4 {\n",
       "    font-family: 'Philosopher', serif;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-family: 'Alegreya Sans', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 16pt;\n",
       "    color: grey;\n",
       "    font-style: italic;\n",
       "    margin-bottom: .1em;\n",
       "    margin-top: 0.1em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render h6 {\n",
       "    font-family: 'PT Mono', sans-serif;\n",
       "    font-weight: 300;\n",
       "    font-size: 10pt;\n",
       "    color: grey;\n",
       "    margin-bottom: 1px;\n",
       "    margin-top: 1px;\n",
       "}\n",
       "\n",
       ".text_cell_render em {\n",
       "    font-family: 'Philosopher', sans-serif;\n",
       "    color:        blue;\n",
       "    background-color: rgb(255,220,180);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   100;\n",
       "}\n",
       "\n",
       ".text_cell_render b {\n",
       "    color:            rgb(255,195,195);\n",
       "    background-color: rgb(0,0,0);\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render u {\n",
       "    color:            blue;\n",
       "    font-size:    110%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   650;\n",
       "}\n",
       "\n",
       ".text_cell_render tt {\n",
       "    font-size:    120%;\n",
       "    margin-left:   2px;\n",
       "    margin-right:  2px;\n",
       "    font-weight:   150;\n",
       "}\n",
       "\n",
       ".Codemirror {\n",
       "    font-family: \"PT Mono\";\n",
       "    font-size: 100%;\n",
       "}\n",
       "\n",
       "#fancy {\n",
       "    font-family:      Georgia;\n",
       "    position:         relative;\n",
       "    float:            left;\n",
       "    border:           2px solid red;\n",
       "    width:            600px;\n",
       "    padding-left:     20px;\n",
       "    padding-right:    20px;\n",
       "    padding-top:      10px;\n",
       "    font-family:      'Sacramento', cursive;\n",
       "    font-size:        26px;\n",
       "    background-color: #F4EBF3;\n",
       "    border-radius:    15px;\n",
       "}\n",
       "\n",
       "</Style>\n",
       "\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a68011",
   "metadata": {},
   "source": [
    "The following example has been extracted from the official documentation of Ply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c3ba",
   "metadata": {},
   "source": [
    "## A Tokenizer for Numbers and the Arithmetical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc3416",
   "metadata": {},
   "source": [
    "The module `chevrotain` contains the code that is necessary to create a scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f23e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "up to date, audited 8 packages in 959ms\n",
      "\n",
      "found 0 vulnerabilities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const { execSync } = await import('child_process');\n",
    "console.log(execSync('npm install chevrotain@10').toString());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c26f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import { createToken, Lexer, IToken, ILexingError } from \"chevrotain\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c960",
   "metadata": {},
   "source": [
    "We start with a definition of the <em style=\"color:blue\">tokens</em>.  Note that all token names have to start with \n",
    "a capital letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca346672",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Plus    = createToken({ name: \"PLUS\",    pattern: /\\+/ });\n",
    "const Minus   = createToken({ name: \"MINUS\",   pattern: /-/ });\n",
    "const Times   = createToken({ name: \"TIMES\",   pattern: /\\*/ });\n",
    "const Divide  = createToken({ name: \"DIVIDE\",  pattern: /\\// });\n",
    "const LParen  = createToken({ name: \"LPAREN\",  pattern: /\\(/ });\n",
    "const RParen  = createToken({ name: \"RPAREN\",  pattern: /\\)/ });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b02a11",
   "metadata": {},
   "source": [
    "If we need to transform the value of a token, we can define the token via a function.  In that case, the first line of the function \n",
    "has to be a string that is a regular expression.  This regular expression then defines the token.  After that,\n",
    "we can add code to transform the token.  The string that makes up the token is stored in `t.value`.  Below, this string\n",
    "is cast into an integer via the predefined function `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "293667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "const NumberLiteral = createToken({ name: \"NUMBER\", pattern: /(?:\\d*\\.\\d+|\\d+)/ });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246263e7",
   "metadata": {},
   "source": [
    "The rule below is used to keep track of line numbers. We use the function `len` since there might be\n",
    "more than one newline.  The member variable `lexer.lineno` keeps track of the current line number.  This variable\n",
    "is maintained so that we are able to specify the precise location of unkown characters in error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f4e2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Newline = createToken({ name: \"NEWLINE\", pattern: /\\n+/ });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fa01fc",
   "metadata": {},
   "source": [
    "The keyword `t_ignore` specifies those characters that should be discarded.\n",
    "In the following cell it specifies that space characters and tabulator characters are to be ignored.  Note that we **must not** use a raw string here, since otherwise `\\t` would not denote a tabulator character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "const WhiteSpace = createToken({ name: \"WS\", pattern: /[ \\t\\r]+/, group: Lexer.SKIPPED });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86155c37",
   "metadata": {},
   "source": [
    "All characters not recognized by any of the defined tokens are handled by the function t_error. The function t.lexer.skip(1) skips one character, which is the character that has not been recognized. Scanning resumes after this character has been discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fef514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function t_error(errors: ILexingError[]): void {\n",
    "  if (errors.length === 0) return;\n",
    "\n",
    "  console.error(\"Lexing errors detected:\");\n",
    "\n",
    "  for (const err of errors) {\n",
    "    console.error(`  → ${err.message}`);\n",
    "    if (err.line !== undefined && err.column !== undefined) {\n",
    "      console.error(`    at line ${err.line}, column ${err.column}`);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Optional: throw an exception to stop execution\n",
    "  // throw new Error(\"Lexing failed due to errors.\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aacb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "const allTokens = [WhiteSpace, Newline, Plus, Minus, Times, Divide, LParen, RParen, NumberLiteral];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415e457",
   "metadata": {},
   "source": [
    "Below the function `lex.lex()` creates the lexer specified above.  Since this code is expected to be part \n",
    "of some Python file but really isn't part of a file since it is placed in a Jupyter notebook we have to set the variable \n",
    "`__file__` manually to fool the system into believing that the code given above is located in a file \n",
    "called `hugo.py`.  The name `hugo` is totally irrelevant and could be replaced by any other name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f8a1b",
   "metadata": {},
   "source": [
    "Now `lexer` is the scanner that has been created by the previous command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c406727",
   "metadata": {},
   "outputs": [],
   "source": [
    "const lexer = new Lexer(allTokens, { positionTracking: \"full\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cc70c",
   "metadata": {},
   "source": [
    "Lets test the generated scanner, that is stored in `lexer`, with the following string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d554d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data = `\n",
    "  3 + 4 * 10 + 007 + (-20) * 2\n",
    "  42\n",
    "  a\n",
    "  b\n",
    "  c\n",
    "`;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bf50f",
   "metadata": {},
   "source": [
    "Let us feed the scanner with the string `data`.  This is done by calling the method `input` of the generated scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8db12dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  3 + 4 * 10 + 007 + (-20) * 2\n",
      "  42\n",
      "  a\n",
      "  b\n",
      "  c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "console.log(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ed6a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "function runLexer(input: string): void {\n",
    "  const result = lexer.tokenize(input);\n",
    "\n",
    "      t_error(result.errors);\n",
    "\n",
    "  if (result.errors.length === 0) {\n",
    "    console.log(\"Tokens:\");\n",
    "    for (const token of result.tokens) {\n",
    "      console.log(\n",
    "        `${token.image} → ${token.tokenType.name} (line ${token.startLine}, column ${token.startColumn})`\n",
    "      );\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c2c40b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mLexing errors detected:\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->a<- at offset: 39, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 4, column 3\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->b<- at offset: 43, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 5, column 3\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->c<- at offset: 47, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 6, column 3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "runLexer(data);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c75886",
   "metadata": {},
   "source": [
    "I have set the line number to `1` before scanning in order to be able to run the scanner multiple times, since each time the scanner runs the line number is changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "552ee06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mLexing errors detected:\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->a<- at offset: 39, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 4, column 3\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->b<- at offset: 43, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 5, column 3\u001b[39m\n",
      "\u001b[31m  → unexpected character: ->c<- at offset: 47, skipped 1 characters.\u001b[39m\n",
      "\u001b[31m    at line 6, column 3\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "runLexer(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55897968",
   "metadata": {},
   "source": [
    "Now we put the lexer to work by using it as an *iterable*.  This way, we can simply iterate over all the tokens that our scanner recognizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "741f6c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬───────────┬──────────────────────────┐\n",
      "│ (index) │ name      │ pattern                  │\n",
      "├─────────┼───────────┼──────────────────────────┤\n",
      "│ 0       │ \u001b[32m'WS'\u001b[39m      │ \u001b[32m'/[ \\\\t\\\\r]+/'\u001b[39m           │\n",
      "│ 1       │ \u001b[32m'NEWLINE'\u001b[39m │ \u001b[32m'/\\\\n+/'\u001b[39m                 │\n",
      "│ 2       │ \u001b[32m'PLUS'\u001b[39m    │ \u001b[32m'/\\\\+/'\u001b[39m                  │\n",
      "│ 3       │ \u001b[32m'MINUS'\u001b[39m   │ \u001b[32m'/-/'\u001b[39m                    │\n",
      "│ 4       │ \u001b[32m'TIMES'\u001b[39m   │ \u001b[32m'/\\\\*/'\u001b[39m                  │\n",
      "│ 5       │ \u001b[32m'DIVIDE'\u001b[39m  │ \u001b[32m'/\\\\//'\u001b[39m                  │\n",
      "│ 6       │ \u001b[32m'LPAREN'\u001b[39m  │ \u001b[32m'/\\\\(/'\u001b[39m                  │\n",
      "│ 7       │ \u001b[32m'RPAREN'\u001b[39m  │ \u001b[32m'/\\\\)/'\u001b[39m                  │\n",
      "│ 8       │ \u001b[32m'NUMBER'\u001b[39m  │ \u001b[32m'/(?:\\\\d*\\\\.\\\\d+|\\\\d+)/'\u001b[39m │\n",
      "└─────────┴───────────┴──────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "console.table(\n",
    "  allTokens.map(t => ({\n",
    "    name: t.name,\n",
    "    pattern: t.PATTERN.toString(),\n",
    "  }))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681a1b8",
   "metadata": {},
   "source": [
    "We see that the generated tokens contain four pieces of information:\n",
    " 1. The *type* of the token.\n",
    " 2. The *value* of the token.  This is either a number or a string.\n",
    " 3. The *line number* of the token.  The line number starts with 1.\n",
    "    However, note that the first line of `data` is empty.\n",
    " 4. The *character count*.  For example, the last token is the $54^{\\textrm{th}}$ character.\n",
    "    The character count starts with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7ba02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
