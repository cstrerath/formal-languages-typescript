{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d894ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style><link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Arvo:400,700,400italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=PT+Mono' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Shadows+Into+Light' rel='stylesheet' type='text/css'>\r\n",
       "<link href='http://fonts.googleapis.com/css?family=Philosopher:400,700,400italic,700italic' rel='stylesheet' type='text/css'>\r\n",
       "<link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\r\n",
       "\r\n",
       "<style>\r\n",
       "\r\n",
       "@font-face {\r\n",
       "    font-family: \"Computer Modern\";\r\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\r\n",
       "}\r\n",
       "\r\n",
       ".container { width: 100% }\r\n",
       "\r\n",
       "/* Formatting for header cells */\r\n",
       ".text_cell_render h1 {\r\n",
       "    font-family: 'Philosopher', sans-serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 2.2em;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(0, 80, 120);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\t\r\n",
       ".text_cell_render h2 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "    font-weight: 400;\r\n",
       "    font-size: 1.9em;\r\n",
       "    line-height: 100%;\r\n",
       "    color: rgb(200,100,0);\r\n",
       "    margin-bottom: 0.1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\t\r\n",
       "\r\n",
       ".text_cell_render h3 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "    margin-top:12px;\r\n",
       "    margin-bottom: 3px;\r\n",
       "    font-style: italic;\r\n",
       "    color: rgb(94,127,192);\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h4 {\r\n",
       "    font-family: 'Philosopher', serif;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h5 {\r\n",
       "    font-family: 'Alegreya Sans', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 16pt;\r\n",
       "    color: grey;\r\n",
       "    font-style: italic;\r\n",
       "    margin-bottom: .1em;\r\n",
       "    margin-top: 0.1em;\r\n",
       "    display: block;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render h6 {\r\n",
       "    font-family: 'PT Mono', sans-serif;\r\n",
       "    font-weight: 300;\r\n",
       "    font-size: 10pt;\r\n",
       "    color: grey;\r\n",
       "    margin-bottom: 1px;\r\n",
       "    margin-top: 1px;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render em {\r\n",
       "    font-family: 'Philosopher', sans-serif;\r\n",
       "    color:        blue;\r\n",
       "    background-color: rgb(255,220,180);\r\n",
       "    font-size:    110%;\r\n",
       "    margin-left:   2px;\r\n",
       "    margin-right:  2px;\r\n",
       "    font-weight:   100;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render b {\r\n",
       "    color:            rgb(255,195,195);\r\n",
       "    background-color: rgb(0,0,0);\r\n",
       "    font-size:    110%;\r\n",
       "    margin-left:   2px;\r\n",
       "    margin-right:  2px;\r\n",
       "    font-weight:   650;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render u {\r\n",
       "    color:            blue;\r\n",
       "    font-size:    110%;\r\n",
       "    margin-left:   2px;\r\n",
       "    margin-right:  2px;\r\n",
       "    font-weight:   650;\r\n",
       "}\r\n",
       "\r\n",
       ".text_cell_render tt {\r\n",
       "    font-size:    120%;\r\n",
       "    margin-left:   2px;\r\n",
       "    margin-right:  2px;\r\n",
       "    font-weight:   150;\r\n",
       "}\r\n",
       "\r\n",
       ".Codemirror {\r\n",
       "    font-family: \"PT Mono\";\r\n",
       "    font-size: 100%;\r\n",
       "}\r\n",
       "\r\n",
       "#fancy {\r\n",
       "    font-family:      Georgia;\r\n",
       "    position:         relative;\r\n",
       "    float:            left;\r\n",
       "    border:           2px solid red;\r\n",
       "    width:            600px;\r\n",
       "    padding-left:     20px;\r\n",
       "    padding-right:    20px;\r\n",
       "    padding-top:      10px;\r\n",
       "    font-family:      'Sacramento', cursive;\r\n",
       "    font-size:        26px;\r\n",
       "    background-color: #F4EBF3;\r\n",
       "    border-radius:    15px;\r\n",
       "}\r\n",
       "\r\n",
       "</Style>\r\n",
       "\r\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a68011",
   "metadata": {},
   "source": [
    "The following example has been adapted from the official Ply documentation and ported to TypeScript using Chevrotain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c3ba",
   "metadata": {},
   "source": [
    "## A Tokenizer for Numbers and the Arithmetical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc3416",
   "metadata": {},
   "source": [
    "The module `chevrotain` contains the code that is necessary to create a scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f23e166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "up to date, audited 9 packages in 2s\n",
      "\n",
      "found 0 vulnerabilities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "const { execSync } = await import('child_process');\n",
    "console.log(execSync('npm install chevrotain@10').toString());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c26f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import { createToken, Lexer, IToken, ILexingError } from \"chevrotain\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c960",
   "metadata": {},
   "source": [
    "We start with the definition of <em style=\"color:blue\">tokens</em>.\n",
    "\n",
    "In Chevrotain, each token is created using the `createToken` function, which takes a configuration object with a `name` and a `pattern` (regular expression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca346672",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Plus    = createToken({ name: \"PLUS\",    pattern: /\\+/ });\n",
    "const Minus   = createToken({ name: \"MINUS\",   pattern: /-/ });\n",
    "const Times   = createToken({ name: \"TIMES\",   pattern: /\\*/ });\n",
    "const Divide  = createToken({ name: \"DIVIDE\",  pattern: /\\// });\n",
    "const LParen  = createToken({ name: \"LPAREN\",  pattern: /\\(/ });\n",
    "const RParen  = createToken({ name: \"RPAREN\",  pattern: /\\)/ });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b02a11",
   "metadata": {},
   "source": [
    "The pattern for numbers uses the regular expression `/0|[1-9][0-9]*/`.\n",
    "\n",
    "This means a number is either:\n",
    "- Exactly `0`, or\n",
    "- Starts with a digit from 1-9 followed by any number of digits\n",
    "\n",
    "This prevents leading zeros like `007`, which would be tokenized as three separate numbers: `0`, `0`, `7`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "const NumberLiteral = createToken({ \n",
    "  name: \"NUMBER\", \n",
    "  pattern: /0|[1-9][0-9]*/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246263e7",
   "metadata": {},
   "source": [
    "Characters that should be ignored (whitespace, tabs, newlines) are marked with `group: Lexer.SKIPPED`.\n",
    "\n",
    "This tells Chevrotain to:\n",
    "- Recognize these tokens for proper position tracking (line and column numbers)\n",
    "- Not include them in the output token stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4e2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Newline = createToken({\n",
    "    name: \"NEWLINE\",\n",
    "    pattern: /\\n+/,\n",
    "    group: Lexer.SKIPPED\n",
    "});\n",
    "\n",
    "const WhiteSpace = createToken({\n",
    "    name: \"WS\",\n",
    "    pattern: /[ \\t\\r]+/,\n",
    "    group: Lexer.SKIPPED\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6935b",
   "metadata": {},
   "source": [
    "Finally, we collect all token definitions in an array.\n",
    "\n",
    "**Important:** The order matters! Chevrotain tries to match tokens in the order they appear in this array. Whitespace and newlines should come first to ensure they are recognized before other patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aacb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "const allTokens = [WhiteSpace, Newline, Plus, Minus, Times, Divide, LParen, RParen, NumberLiteral];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415e457",
   "metadata": {},
   "source": [
    "We can inspect all defined tokens and their patterns using a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d23e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬───────────┬───────────────────┐\n",
      "│ (index) │ name      │ pattern           │\n",
      "├─────────┼───────────┼───────────────────┤\n",
      "│ 0       │ \u001b[32m'WS'\u001b[39m      │ \u001b[32m'/[ \\\\t\\\\r]+/'\u001b[39m    │\n",
      "│ 1       │ \u001b[32m'NEWLINE'\u001b[39m │ \u001b[32m'/\\\\n+/'\u001b[39m          │\n",
      "│ 2       │ \u001b[32m'PLUS'\u001b[39m    │ \u001b[32m'/\\\\+/'\u001b[39m           │\n",
      "│ 3       │ \u001b[32m'MINUS'\u001b[39m   │ \u001b[32m'/-/'\u001b[39m             │\n",
      "│ 4       │ \u001b[32m'TIMES'\u001b[39m   │ \u001b[32m'/\\\\*/'\u001b[39m           │\n",
      "│ 5       │ \u001b[32m'DIVIDE'\u001b[39m  │ \u001b[32m'/\\\\//'\u001b[39m           │\n",
      "│ 6       │ \u001b[32m'LPAREN'\u001b[39m  │ \u001b[32m'/\\\\(/'\u001b[39m           │\n",
      "│ 7       │ \u001b[32m'RPAREN'\u001b[39m  │ \u001b[32m'/\\\\)/'\u001b[39m           │\n",
      "│ 8       │ \u001b[32m'NUMBER'\u001b[39m  │ \u001b[32m'/0|[1-9][0-9]*/'\u001b[39m │\n",
      "└─────────┴───────────┴───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "console.table(\n",
    "  allTokens.map(t => ({\n",
    "    name: t.name,\n",
    "    pattern: t.PATTERN.toString(),\n",
    "  }))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f8a1b",
   "metadata": {},
   "source": [
    "Now we create the lexer using Chevrotain's `Lexer` class.\n",
    "\n",
    "The option `positionTracking: \"full\"` ensures that we get complete position information (line, column, offset) for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c406727",
   "metadata": {},
   "outputs": [],
   "source": [
    "const lexer = new Lexer(allTokens, { positionTracking: \"full\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cc70c",
   "metadata": {},
   "source": [
    "Let's test the generated lexer with the following string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d554d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data = `\n",
    "       3 + 4 * 10 + 007 + (-20) * 2\n",
    "       42\n",
    "       a\n",
    "       `;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bf50f",
   "metadata": {},
   "source": [
    "Here is the input string we will tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8db12dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       3 + 4 * 10 + 007 + (-20) * 2\n",
      "       42\n",
      "       a\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "console.log(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb486a7",
   "metadata": {},
   "source": [
    "Now we tokenize the input string by calling the `tokenize` method.\n",
    "\n",
    "We then iterate over all recognized tokens and display them. Any unrecognized characters will be reported as errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed6a706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexToken(NUMBER,'3',2,8)\n",
      "LexToken(PLUS,'+',2,10)\n",
      "LexToken(NUMBER,'4',2,12)\n",
      "LexToken(TIMES,'*',2,14)\n",
      "LexToken(NUMBER,'10',2,16)\n",
      "LexToken(PLUS,'+',2,19)\n",
      "LexToken(NUMBER,'0',2,21)\n",
      "LexToken(NUMBER,'0',2,22)\n",
      "LexToken(NUMBER,'7',2,23)\n",
      "LexToken(PLUS,'+',2,25)\n",
      "LexToken(LPAREN,'(',2,27)\n",
      "LexToken(MINUS,'-',2,28)\n",
      "LexToken(NUMBER,'20',2,29)\n",
      "LexToken(RPAREN,')',2,31)\n",
      "LexToken(TIMES,'*',2,33)\n",
      "LexToken(NUMBER,'2',2,35)\n",
      "LexToken(NUMBER,'42',3,44)\n",
      "Illegal character 'a' at line 4.\n",
      "This is the 54th character.\n"
     ]
    }
   ],
   "source": [
    "// Tokenize the input\n",
    "const result = lexer.tokenize(data);\n",
    "\n",
    "// Display all tokens\n",
    "for (const token of result.tokens) {\n",
    "  const displayValue = token.image.replace(/\\n/g, '\\\\n');\n",
    "  console.log(`LexToken(${token.tokenType.name},'${displayValue}',${token.startLine},${token.startOffset})`);\n",
    "}\n",
    "\n",
    "// Display errors (if any)\n",
    "for (const error of result.errors) {\n",
    "  const char = error.message.match(/->(.)<-/)?.[1] || '?';\n",
    "  console.log(`Illegal character '${char}' at line ${error.line}.`);\n",
    "  console.log(`This is the ${error.offset}th character.`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681a1b8",
   "metadata": {},
   "source": [
    "We see that each generated token contains the following information:\n",
    "\n",
    "1. The **type** of the token (e.g., `NUMBER`, `PLUS`)\n",
    "2. The **value** of the token - the actual matched string\n",
    "3. The **line number** - starts at 1 (note that the first line of `data` is empty)\n",
    "4. The **character offset** - the position in the input string, starts at 0\n",
    "\n",
    "For example, the character `a` at line 4 is the 54th character in the input string."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
