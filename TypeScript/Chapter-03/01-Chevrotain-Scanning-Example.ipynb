{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d894ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css: string = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a68011",
   "metadata": {},
   "source": [
    "The following example has been adapted from the official Ply documentation and ported to TypeScript using Chevrotain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49c3ba",
   "metadata": {},
   "source": [
    "## A Tokenizer for Numbers and the Arithmetical Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc3416",
   "metadata": {},
   "source": [
    "The module `chevrotain` contains the code that is necessary to create a scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c26f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import { createToken, Lexer, TokenType, IToken, ILexingError, ILexingResult } from \"chevrotain\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c960",
   "metadata": {},
   "source": [
    "We start with the definition of <em style=\"color:blue\">tokens</em>.\n",
    "\n",
    "In Chevrotain, each token is created using the `createToken` function, which takes a configuration object with a `name` and a `pattern` (regular expression) which returns a `TokenType`-Object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca346672",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Plus : TokenType    = createToken({ name: \"PLUS\",    pattern: /\\+/ });\n",
    "const Minus : TokenType   = createToken({ name: \"MINUS\",   pattern: /-/ });\n",
    "const Times : TokenType   = createToken({ name: \"TIMES\",   pattern: /\\*/ });\n",
    "const Divide : TokenType  = createToken({ name: \"DIVIDE\",  pattern: /\\// });\n",
    "const LParen : TokenType  = createToken({ name: \"LPAREN\",  pattern: /\\(/ });\n",
    "const RParen : TokenType  = createToken({ name: \"RPAREN\",  pattern: /\\)/ });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b02a11",
   "metadata": {},
   "source": [
    "The pattern for numbers uses the regular expression `/0|[1-9][0-9]*/`.\n",
    "\n",
    "This means a number is either:\n",
    "- Exactly `0`, or\n",
    "- Starts with a digit from 1-9 followed by any number of digits\n",
    "\n",
    "This prevents leading zeros like `007`, which would be tokenized as three separate numbers: `0`, `0`, `7`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293667ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "const NumberLiteral = createToken({ \n",
    "  name: \"NUMBER\", \n",
    "  pattern: /0|[1-9][0-9]*/ \n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246263e7",
   "metadata": {},
   "source": [
    "Characters that should be ignored (whitespace, tabs, newlines) are marked with `group: Lexer.SKIPPED`.\n",
    "\n",
    "This tells Chevrotain to:\n",
    "- Recognize these tokens for proper position tracking (line and column numbers)\n",
    "- Not include them in the output token stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Newline : TokenType = createToken({\n",
    "    name: \"NEWLINE\",\n",
    "    pattern: /\\n+/,\n",
    "    group: Lexer.SKIPPED\n",
    "});\n",
    "\n",
    "const WhiteSpace : TokenType = createToken({\n",
    "    name: \"WS\",\n",
    "    pattern: /[ \\t\\r]+/,\n",
    "    group: Lexer.SKIPPED\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6935b",
   "metadata": {},
   "source": [
    "Finally, we collect all token definitions in an array.\n",
    "\n",
    "**Important:** The order matters! Chevrotain tries to match tokens in the order they appear in this array. Whitespace and newlines should come first to ensure they are recognized before other patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aacb678",
   "metadata": {},
   "outputs": [],
   "source": [
    "const allTokens : TokenType[] = [WhiteSpace, Newline, Plus, Minus, Times, Divide, LParen, RParen, NumberLiteral];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415e457",
   "metadata": {},
   "source": [
    "We can inspect all defined tokens and their patterns using a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d23e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.table(\n",
    "  allTokens.map(token => ({\n",
    "    name: token.name,\n",
    "    pattern: token.PATTERN.toString(),\n",
    "  }))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f8a1b",
   "metadata": {},
   "source": [
    "Now we create the lexer using Chevrotain's `Lexer` class.\n",
    "\n",
    "The option `positionTracking: \"full\"` ensures that we get complete position information (line, column, offset) for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c406727",
   "metadata": {},
   "outputs": [],
   "source": [
    "const lexer : Lexer = new Lexer(allTokens, { positionTracking: \"full\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cc70c",
   "metadata": {},
   "source": [
    "Let's test the generated lexer with the following string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data : string = `\n",
    "       3 + 4 * 10 + 007 + (-20) * 2\n",
    "       42\n",
    "       a\n",
    "       `;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083bf50f",
   "metadata": {},
   "source": [
    "Here is the input string we will tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db12dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb486a7",
   "metadata": {},
   "source": [
    "Now we tokenize the input string by calling the `tokenize` method.\n",
    "\n",
    "We then iterate over all recognized tokens and display them. Any unrecognized characters will be reported as errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "const result: ILexingResult = lexer.tokenize(data);\n",
    "\n",
    "for (const token of result.tokens as IToken[]) {\n",
    "  const displayValue: string = token.image.replace(/\\n/g, \"\\\\n\");\n",
    "  console.log(\n",
    "    `LexToken(${token.tokenType.name},'${displayValue}',${token.startLine},${token.startOffset})`\n",
    "  );\n",
    "}\n",
    "\n",
    "for (const error of result.errors as ILexingError[]) {\n",
    "  const charFromMessage: string = error.message.match(/->(.)<-/)?.[1];\n",
    "  const illegalChar: string = charFromMessage || data.substr(error.offset, error.length) || \"?\";\n",
    "\n",
    "  console.log(`Illegal character '${illegalChar}' at line ${error.line}.`);\n",
    "  console.log(`This is the ${error.offset}th character.`);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f681a1b8",
   "metadata": {},
   "source": [
    "We see that each generated token contains the following information:\n",
    "\n",
    "1. The **type** of the token (e.g., `NUMBER`, `PLUS`)\n",
    "2. The **value** of the token - the actual matched string\n",
    "3. The **line number** - starts at 1 (note that the first line of `data` is empty)\n",
    "4. The **character offset** - the position in the input string, starts at 0\n",
    "\n",
    "For example, the character `a` at line 4 is the 54th character in the input string."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
