{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48bae9",
   "metadata": {},
   "source": [
    "# Converting <span style=\"font-variant:small-caps;\">Html</span> to Text\n",
    "\n",
    "This notebook shows how we can use the package [`ply`](https://ply.readthedocs.io/en/latest/ply.html)\n",
    "to extract the text that is embedded in an <span style=\"font-variant:small-caps;\">Html</span> file.  \n",
    "In order to be concise, it only supports a small subset of \n",
    "<span style=\"font-variant:small-caps;\">Html</span>.  Below is the content of my old\n",
    "<a href=\"http://wwwlehre.dhbw-stuttgart.de/~stroetma/\">web page</a> that I had used when I was still working at the DHBW Stuttgart.  The goal of this notebook is to write \n",
    "a scanner that is able to extract the text from this web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e774804",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data = `\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Homepage of Prof. Dr. Karl Stroetmann</title>\n",
    "    <link type=\"text/css\" rel=\"stylesheet\" href=\"style.css\" />\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Rochester&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Pacifico&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Cabin+Sketch&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\n",
    "  </head>\n",
    "  <body>\n",
    "    <hr/>\n",
    "\n",
    "    <div id=\"table\">\n",
    "      <header>\n",
    "        <h1 id=\"name\">Prof. Dr. Karl Stroetmann</h1>\n",
    "      </header>\n",
    "\n",
    "      <div id=\"row1\">\n",
    "        <div class=\"right\">\n",
    "          <a id=\"dhbw\" href=\"http://www.ba-stuttgart.de\">Duale Hochschule Baden-W&uuml;rttemberg</a>\n",
    "          <br/>Coblitzallee 1-9\n",
    "          <br/>68163 Mannheim\n",
    "          <br/>Germany\n",
    "\t  <br>\n",
    "          <br/>Office: &nbsp;&nbsp;&nbsp; Raum 344B\n",
    "          <br/>Phone:&nbsp;&nbsp;&nbsp; +49 621 4105-1376\n",
    "          <br/>Fax:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +49 621 4105-1194\n",
    "          <br/>Skype: &nbsp;&nbsp;&nbsp; karlstroetmann\n",
    "        </div>  \n",
    "\n",
    "\n",
    "        <div id=\"links\">\n",
    "          <strong class=\"some\">Some links:</strong>\n",
    "          <ul class=\"inlink\">\n",
    "            <li class=\"inlink\">\n",
    "\t      My <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">lecture notes</a>,\n",
    "              as well as the programs presented in class, can be found\n",
    "              at <br>\n",
    "              <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">https://github.com/karlstroetmann</a>.\n",
    "              \n",
    "            </li>\n",
    "            <li class=\"inlink\">Most of my papers can be found at <a class=\"inlink\" href=\"https://www.researchgate.net/\">researchgate.net</a>.</li>\n",
    "            <li class=\"inlink\">The programming language SetlX can be downloaded at <br>\n",
    "              <a href=\"http://randoom.org/Software/SetlX\"><tt class=\"inlink\">http://randoom.org/Software/SetlX</tt></a>.\n",
    "            </li>\n",
    "          </ul>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"intro\">\n",
    "      As I am getting old and wise, I have to accept the limits of\n",
    "      my own capabilities.  I have condensed these deep philosophical\n",
    "      insights into a most beautiful pearl of poetry.  I would like \n",
    "      to share these humble words of wisdom:\n",
    "      \n",
    "      <div class=\"poetry\">\n",
    "        I am a teacher by profession,    <br>\n",
    "        mostly really by obsession;      <br>\n",
    "        But even though I boldly try,    <br>\n",
    "        I just cannot teach <a href=\"flying-pig.jpg\" id=\"fp\">pigs</a> to fly.</br>\n",
    "        Instead, I slaughter them and fry.\n",
    "      </div>\n",
    "      \n",
    "      <div class=\"citation\">\n",
    "        <div class=\"quote\">\n",
    "          Any sufficiently advanced poetry is indistinguishable from divine wisdom.\n",
    "        </div>\n",
    "        <div id=\"sign\">His holiness Pope Hugo &#8555;.</div>\n",
    "      </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.html(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba750b4",
   "metadata": {},
   "source": [
    "The original web page is still available at https://wwwlehre.dhbw-stuttgart.de/~stroetma/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f105f6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b61710",
   "metadata": {},
   "source": [
    "We will use the package [Chevrotain](https://chevrotain.io/documentation/0_7_2/index.html) to remove the \n",
    "<span style=\"font-variant:small-caps;\">Html</span> tags and extract the text that\n",
    "is embedded in the <span style=\"font-variant:small-caps;\">Html</span> shown above.\n",
    "In this example, we will only use the scanner that is provided by the module `Lexer`. \n",
    "Hence we import the module `Lexer` that contains the scanner generator from `Chevrotain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const { execSync } = await import('child_process');\n",
    "console.log(execSync('npm install chevrotain@10').toString());\n",
    "console.log(execSync('npm install entities').toString());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1898f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { createToken,Lexer,ITokenConfig,TokenType } from \"chevrotain\";\n",
    "import { decodeHTML } from \"entities\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dba652",
   "metadata": {},
   "source": [
    "## Definition of the States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec527ec8",
   "metadata": {},
   "source": [
    "Once we are inside an <span style=\"font-variant:small-caps;\">Html</span> header or inside of some\n",
    "*JavaScript* code the rules of the scanning game change.  Therefore, we declare two new <em style=\"color:blue\">exclusive scanner states</em>:\n",
    "- `header` is the state the scanner is in while it is scanning an \n",
    "  <span style=\"font-variant:small-caps;\">Html</span> header.\n",
    "- `script` is the state of the scanner while scanning *JavaScript* code.  \n",
    "\n",
    "These states are *exclusive* states and hence the other token definitions do not apply in these\n",
    "states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1863ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [ ('header', 'exclusive'),\n",
    "           ('script', 'exclusive')\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef099264",
   "metadata": {},
   "source": [
    "## Token Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c220b",
   "metadata": {},
   "source": [
    "We proceed to give the definition of the tokens.  Note that none of the function defined below\n",
    "returns a token.  Rather all of these function print the transformation of the \n",
    "<span style=\"font-variant:small-caps;\">Html</span> that they have matched.\n",
    "\n",
    "In this section, we will define the tokens needed to process our exam data.\n",
    "\n",
    "Each token is created using Chevrotain's createToken function, which takes two main parameters:\n",
    "\n",
    "name - A string identifying the token type\n",
    "pattern - A regular expression that defines what strings this token matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa605d1d",
   "metadata": {},
   "source": [
    "### The Definition of the Token `HEAD_START`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687195d7",
   "metadata": {},
   "source": [
    "Once the scanner reads the opening tag `<head>` it switches into the state `header`.  The function `begin` of the lexer can be used to switch into a different scanner state.  In the state `header`, the scanner continues to read and discard characters until the closing tag `</head>` is encountered.  Note that this token is only recognized in the state `INITIAL`.  The state `INITIAL` is the initial state of the scanner, i.e. the scanner always starts in this state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ce835",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HEAD_START = createToken({\n",
    "    name: \"HEAD_START\", \n",
    "    pattern: /<head>/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecb5c9",
   "metadata": {},
   "source": [
    "### The Definition of the Token `SCRIPT_START`\n",
    "\n",
    "Once the scanner reads the opening tag `<script>` it switches into the state `script`.  In this state it will continue to read and discard characters until it sees the closing tag `</script>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const SCRIPT_START = createToken({\n",
    "    name: \"SCRIPT_START\", \n",
    "    pattern: /<script>/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20979ff0",
   "metadata": {},
   "source": [
    "### The Definition of the Token `LINEBREAK``\n",
    "\n",
    "Groups of newline characters are condensed into a single newline character.\n",
    "As we are not interested in the variable `t.lexer.lineno` in this example, we don't have to count the newlines.\n",
    "This token is active in the `INITIAL` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "const LineBreak = createToken({\n",
    "  name: \"LineBreak\",\n",
    "  // Eine oder mehrere Leerzeilen (wie im Notebook: (\\s*\\n\\s*)+)\n",
    "  pattern: /(?:\\s*\\n\\s*)+/,\n",
    "  line_breaks: true\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78b6cd",
   "metadata": {},
   "source": [
    "### The Definition of the Token `TAG`\n",
    "\n",
    "The token `TAG` is defined as any string that starts with the character `<` and ends with the character \n",
    "`>`. Betweens these two characters there has to be a nonzero number of characters that are different from \n",
    "the character `>`.  The text of the token is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "const Tag = createToken({\n",
    "  name: \"Tag\",\n",
    "  pattern: /<[^>]+>/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dfbee",
   "metadata": {},
   "source": [
    "### The Definition of the Token `NAMED_ENTITY`\n",
    "\n",
    "In order to support named <span style=\"font-variant:small-caps;\">Html</span> entities we need to import\n",
    "the dictionary `html5` from the module `html.entities`.  For every named \n",
    "<span style=\"font-variant:small-caps;\">Html</span> entity `e`, `html[e]` is the unicode symbol that is specified by `e`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6452cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(decodeHTML(\"&auml;\")); // √§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71afbfc",
   "metadata": {},
   "source": [
    "The regular expression `&[a-zA-Z]+;?` searches for <span style=\"font-variant:small-caps;\">Html</span>\n",
    "entity names.  These are strings that start with the character `&` followed by the name of the entity, optionally followed by the character `;`.  For example, `&auml;` is the entity name that specifies the German umlaut `√§`.  If a Unicode entity name is found, the corresponding character is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const NamedEntity = createToken({\n",
    "  name: \"NamedEntity\",\n",
    "  pattern: /&[a-zA-Z]+;?/,\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fb671",
   "metadata": {},
   "source": [
    "### The Definition of the Token `UNICODE` \n",
    "\n",
    "The regular expression `&\\#[0-9]+;?` searches for <span style=\"font-variant:small-caps;\">Html</span> entities that specify a unicode character numerically.  The corresponding strings start with the character `&`\n",
    "followed by the character `#` followed by digits and are optionally ended by the character `;`.\n",
    "\n",
    "Note that we had to escape the character `#` with a  backslash because otherwise this character would signal the begin of a comment.\n",
    "\n",
    "Note further that the function `chr` takes a number and returns the corresponding unicode character.\n",
    "For example, `chr(128034)` returns the character `'üê¢'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5147f8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:17 - Cannot find name 'createToken'.\n"
     ]
    }
   ],
   "source": [
    "const Unicode = createToken({\n",
    "  name: \"UnicodeEntity\",\n",
    "  // optionales x/X, Hexadezimal- oder Dezimalzahlen, optionales Semikolon\n",
    "  pattern: /&#[xX]?[0-9a-fA-F]+;?/,\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56ace0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ö´\n"
     ]
    }
   ],
   "source": [
    "String.fromCodePoint(8555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb024ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê¢\n"
     ]
    }
   ],
   "source": [
    "String.fromCodePoint(128034)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e17a1",
   "metadata": {},
   "source": [
    "### The Definition of the Token `ANY` \n",
    "\n",
    "The regular expression `.` matches any character that is different from a newline character.  These characters are printed unmodified.  Note that the scanner tries the regular expressions for a given state in the order that they are defined in this notebook.  Therefore, it is crucial that the function `t_ANY` is defined after all other token definitions for the `INITIAL` state are given.  The `INITIAL` state is the default state of the scanner and therefore the state the scanner is in when it starts scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0090a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "const ANY = createToken({\n",
    "    name: \"ANY\",\n",
    "    pattern: /./\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d090ad",
   "metadata": {},
   "source": [
    "### The Definition of the Token `HEAD_END` \n",
    "\n",
    "The regular expression `</head>` matches the closing head tag.  Note that this regular expression is only\n",
    "active in state `header` as the name of this function starts with `t_header`.  Once the closing tag has been found, the function `lexer.begin` switches the lexer back into the state `INITIAL`, which is the \n",
    "<em style=\"color:blue\">start state</em> of the scanner.  In the state `INITIAL`, all token definitions are active, that do not start with either `t_header` or `t_script`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HEAD_END = createToken({\n",
    "    name: \"HEAD_END\",\n",
    "    pattern: /<\\/head>/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de68e8c",
   "metadata": {},
   "source": [
    "### The Definition of the Token `SCRIPT_END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077291a",
   "metadata": {},
   "source": [
    "The regular expression `</script>` matches the closing script tag.  Note that this regular expression is only\n",
    "active in state `script`.  Once the closing tag has been found, the function `lexer.begin` switches the lexer back into the state `INITIAL`, which is the start state of the scanner.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const SCRIPT_END = createToken({\n",
    "    name: \"SCRIPT_END\",\n",
    "    pattern: /<\\/script>/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afebfd5",
   "metadata": {},
   "source": [
    "### The Definition of the Token `ANY`\n",
    "\n",
    "If the scanner is either in the state `header` or the state `script`, the function \n",
    "`t_header_script_ANY` eats up all characters without echoing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0577e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_header_script_ANY(t):\n",
    "    r'.|\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7144f3",
   "metadata": {},
   "source": [
    "## Error Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adea557",
   "metadata": {},
   "source": [
    "The function `t_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens.  In our implementation we print the first character that could not be matched, discard this character and continue.\n",
    "\n",
    "<b>Note:</b>  Because of our definition for the token `ANY`, there can be no scanning **error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const { tokens, errors } = lexer.tokenize(input);\n",
    "\n",
    "if (errors.length) {\n",
    "  for (const e of errors) {\n",
    "    console.error(`Lexing error at offset ${e.offset}: ${e.message}`);\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ef256",
   "metadata": {},
   "source": [
    "The function `t_header_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens and the scanner is in state `header`.  Actually, this function can never be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c858cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_header_error(t):\n",
    "    print(f\"Illegal character in state 'header': '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b055a",
   "metadata": {},
   "source": [
    "The function `t_script_error` is called when a substring at the beginning of the input can not be matched by any of the regular expressions defined in the various tokens and the scanner is in state `script`.  Actually, this function can never be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_script_error(t):\n",
    "    print(f\"Illegal character in state 'script': '{t.value[0]}'\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8220d1",
   "metadata": {},
   "source": [
    "## Running the Scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d36257",
   "metadata": {},
   "source": [
    "The line below is necessary to trick `ply.lex` into assuming this program is written in an ordinary python file instead of a *Jupyter notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3485bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a70f7",
   "metadata": {},
   "source": [
    "The line below generates the scanner.  Because the option `debug=True` is set, we can see the regular expression that is generated for scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee39fd3",
   "metadata": {},
   "source": [
    "Next, we feed our input string into the generated scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer.input(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb3023f",
   "metadata": {},
   "source": [
    "In order to scan the data that we provided in the last line, we iterate over all tokens generated by our scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70202e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(lexer):\n",
    "    for t in lexer:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan(lexer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
