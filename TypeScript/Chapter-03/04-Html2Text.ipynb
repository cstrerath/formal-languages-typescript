{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { display } from \"tslab\";\n",
    "import { readFileSync } from \"fs\";\n",
    "\n",
    "const css : string = readFileSync(\"../style.css\", \"utf8\");\n",
    "display.html(`<style>${css}</style>`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48bae9",
   "metadata": {},
   "source": [
    "# Converting HTML to Text\n",
    "\n",
    "This notebook demonstrates how to build a simple but effective HTML-to-text converter using **TypeScript** and the powerful parsing library [`chevrotain`](https://chevrotain.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f907e46",
   "metadata": {},
   "source": [
    "## The Goal\n",
    "\n",
    "Our objective is to extract the readable, plain text content from a given HTML document. We will use the HTML source code from the homepage of [Prof. Dr. Karl Stroetmann](http://wwwlehre.dhbw-stuttgart.de/~stroetma/) as our example data. \n",
    "\n",
    "To achieve this, we implement a small **state machine** in TypeScript that distinguishes  \n",
    "between different HTML sections such as `<head>`, `<script>`, and normal text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989673fe",
   "metadata": {},
   "source": [
    "## The Strategy: A State Machine\n",
    "\n",
    "HTML is not a simple, linear format. Some sections, like the `<head>` and `<script>` blocks, should be completely ignored, while the content in the `<body>` should be processed.\n",
    "\n",
    "To handle this, we will implement a simple state machine using Chevrotain's \"Lexer Modes\" feature. Our lexer will switch between different states (or modes) depending on the context:\n",
    "\n",
    "- initial_mode: The default state for processing normal text content.\n",
    "- header_mode: An \"ignore\" state activated when entering a `<head>` tag.\n",
    "- script_mode: An \"ignore\" state activated when entering a `<script>` tag.\n",
    "\n",
    "This approach allows us to create a robust tokenizer that correctly distinguishes between content to be extracted and content to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e774804",
   "metadata": {},
   "outputs": [],
   "source": [
    "const data : string = `\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>Homepage of Prof. Dr. Karl Stroetmann</title>\n",
    "    <link type=\"text/css\" rel=\"stylesheet\" href=\"style.css\" />\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Rochester&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Pacifico&subset=latin,latin-ext\"\n",
    "          rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Cabin+Sketch&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text/css\">\n",
    "    <link href=\"http://fonts.googleapis.com/css?family=Sacramento\" rel=\"stylesheet\" type=\"text/css\">\n",
    "  </head>\n",
    "  <body>\n",
    "    <hr/>\n",
    "\n",
    "    <div id=\"table\">\n",
    "      <header>\n",
    "        <h1 id=\"name\">Prof. Dr. Karl Stroetmann</h1>\n",
    "      </header>\n",
    "\n",
    "      <div id=\"row1\">\n",
    "        <div class=\"right\">\n",
    "          <a id=\"dhbw\" href=\"http://www.ba-stuttgart.de\">Duale Hochschule Baden-W&uuml;rttemberg</a>\n",
    "          <br/>Coblitzallee 1-9\n",
    "          <br/>68163 Mannheim\n",
    "          <br/>Germany\n",
    "\t  <br>\n",
    "          <br/>Office: &nbsp;&nbsp;&nbsp; Raum 344B\n",
    "          <br/>Phone:&nbsp;&nbsp;&nbsp; +49 621 4105-1376\n",
    "          <br/>Fax:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; +49 621 4105-1194\n",
    "          <br/>Skype: &nbsp;&nbsp;&nbsp; karlstroetmann\n",
    "        </div>  \n",
    "\n",
    "\n",
    "        <div id=\"links\">\n",
    "          <strong class=\"some\">Some links:</strong>\n",
    "          <ul class=\"inlink\">\n",
    "            <li class=\"inlink\">\n",
    "\t      My <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">lecture notes</a>,\n",
    "              as well as the programs presented in class, can be found\n",
    "              at <br>\n",
    "              <a class=\"inlink\" href=\"https://github.com/karlstroetmann?tab=repositories\">https://github.com/karlstroetmann</a>.\n",
    "              \n",
    "            </li>\n",
    "            <li class=\"inlink\">Most of my papers can be found at <a class=\"inlink\" href=\"https://www.researchgate.net/\">researchgate.net</a>.</li>\n",
    "            <li class=\"inlink\">The programming language SetlX can be downloaded at <br>\n",
    "              <a href=\"http://randoom.org/Software/SetlX\"><tt class=\"inlink\">http://randoom.org/Software/SetlX</tt></a>.\n",
    "            </li>\n",
    "          </ul>\n",
    "        </div>\n",
    "      </div>\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"intro\">\n",
    "      As I am getting old and wise, I have to accept the limits of\n",
    "      my own capabilities.  I have condensed these deep philosophical\n",
    "      insights into a most beautiful pearl of poetry.  I would like \n",
    "      to share these humble words of wisdom:\n",
    "      \n",
    "      <div class=\"poetry\">\n",
    "        I am a teacher by profession,    <br>\n",
    "        mostly really by obsession;      <br>\n",
    "        But even though I boldly try,    <br>\n",
    "        I just cannot teach <a href=\"flying-pig.jpg\" id=\"fp\">pigs</a> to fly.</br>\n",
    "        Instead, I slaughter them and fry.\n",
    "      </div>\n",
    "      \n",
    "      <div class=\"citation\">\n",
    "        <div class=\"quote\">\n",
    "          Any sufficiently advanced poetry is indistinguishable from divine wisdom.\n",
    "        </div>\n",
    "        <div id=\"sign\">His holiness Pope Hugo &#8555;.</div>\n",
    "      </div>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db07d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display.html(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba750b4",
   "metadata": {},
   "source": [
    "The original web page is still available at https://wwwlehre.dhbw-stuttgart.de/~stroetma/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f105f6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b61710",
   "metadata": {},
   "source": [
    "Before we can build our HTML lexer, we need to install and import the necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3935a",
   "metadata": {},
   "source": [
    "We use two packages for this project:\n",
    "\n",
    "- `chevrotain`: A powerful parsing toolkit that provides the lexer functionality we need\n",
    "- `entities`: A utility library for decoding HTML entities (like `&uuml;` ‚Üí √º)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb9e79",
   "metadata": {},
   "source": [
    "From Chevrotain, we import the core components needed for building our lexer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1898f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { createToken, Lexer, tokenMatcher, TokenType, IToken, ILexingError, ILexingResult } from \"chevrotain\";\n",
    "import { decodeHTML } from \"entities\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb2c3e",
   "metadata": {},
   "source": [
    "- `createToken`: Function to define individual token types\n",
    "- `Lexer`: The lexer class that will tokenize our HTML input\n",
    "- `tokenMatcher`: Utility function to safely check if a token matches a specific type\n",
    "- `TokenType`: TypeScript interface for token type definitions (return type of `createToken`)\n",
    "- `IToken`: TypeScript interface for token objects (individual tokens in the result)\n",
    "- `ILexingError`: TypeScript interface for lexing errors\n",
    "- `ILexingResult`: TypeScript interface for the tokenization result object\n",
    "- `decodeHTML`: Function to convert HTML entities to Unicode characters\n",
    "\n",
    "With these imports in place, we're ready to define our tokens and build the lexer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef099264",
   "metadata": {},
   "source": [
    "## Token Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c220b",
   "metadata": {},
   "source": [
    "In this section, we define the tokens needed to process HTML content and extract plain text. In Chevrotain, token definitions are declarative and separate from the processing logic.\n",
    "\n",
    "Each token is created using Chevrotain's `createToken` function, which takes a configuration object with key properties:\n",
    "\n",
    "- `name`: A string identifier for the token type\n",
    "- `pattern`: A regular expression defining what strings this token matches\n",
    "- `push_mode`: Switches the lexer to a diffrent mode when this token is matched\n",
    "- `pop_mode`: Returns the lexer to the previous mode\n",
    "- `group`: Controls whether tokens appear in the output (e.g. Lexer.SKIPPED)\n",
    "- `line_breaks`: Indicates if the pattern can contain newlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa605d1d",
   "metadata": {},
   "source": [
    "### The Definition of the Token `HEAD_START`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687195d7",
   "metadata": {},
   "source": [
    "When the scanner encounters the opening tag `<head>`, it needs to switch into a special mode where all content is ignored until the closing `</head>` tag appears.\n",
    "\n",
    "In Chevrotain, mode switching is handled declaratively using the `push_mode` property. This token pushes the lexer into `header_mode`, where a different set of token rules becomes active. The token is only recognized in the default `initial_mode` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ce835",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HEAD_START : TokenType = createToken({\n",
    "  name: \"HEAD_START\",\n",
    "  pattern: /<head>/i,\n",
    "  push_mode: \"header_mode\"\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238769a3",
   "metadata": {},
   "source": [
    "The pattern `/<head>/i` uses the i flag for case-insensitive matching, so it will match `<head>`, `<HEAD>`, or any other case variation.‚Äã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ecb5c9",
   "metadata": {},
   "source": [
    "### The Definition of the Token `SCRIPT_START`\n",
    "\n",
    "Similar to `HEAD_START`, when the scanner reads an opening `<script>` tag, it switches into `script_mode`. In this mode, all content is discarded until the closing `</script>` tag is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "const SCRIPT_START : TokenType = createToken({\n",
    "  name: \"SCRIPT_START\",\n",
    "  pattern: /<script\\b[^>]*>/i,\n",
    "  push_mode: \"script_mode\"\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586fe2",
   "metadata": {},
   "source": [
    "The pattern `/<script\\b[^>]*>/i` is more sophisticated than a simple `<script>` match:\n",
    "\n",
    "- `\\b` ensures a word boundary after \"script\" (preventing matches like `<scripting>`)\n",
    "- `[^>]*` matches any attributes that might follow (e.g., `<script type=\"text/javascript\">`)\n",
    "- The `i` flag makes it case-insensitive\n",
    "\n",
    "This token transitions the lexer to `script_mode`, where JavaScript code embedded in the HTML will be ignored rather than extracted as text.‚Äã"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20979ff0",
   "metadata": {},
   "source": [
    "### The Definition of the Token `LINEBREAK`\n",
    "\n",
    "The `LINEBREAK` token handles whitespace and newline characters in the HTML document. Instead of preserving every single newline and space, we condense multiple consecutive whitespace-newline sequences into a single newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff3dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "const LINEBREAK : TokenType = createToken({\n",
    "  name: \"LINEBREAK\",\n",
    "  pattern: /(\\s*\\n\\s*)+/,\n",
    "  line_breaks: true\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1d325",
   "metadata": {},
   "source": [
    "The pattern `(/\\s*\\n\\s*)+/` matches one or more sequences of:\n",
    "\n",
    "- Optional whitespace (`\\s*`)\n",
    "- A newline character (`\\n`)\n",
    "- Optional whitespace again (`\\s*`)\n",
    "\n",
    "The `line_breaks: true` property is crucial - it tells Chevrotain that this token can contain newline characters, allowing the lexer to correctly track line and column positions in the source document. This token is only active in `initial_mode`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78b6cd",
   "metadata": {},
   "source": [
    "### The Definition of the Token `TAG`\n",
    "\n",
    "The `TAG` token matches any generic HTML tag that isn't specifically handled by other tokens (like `HEAD_START` or `SCRIPT_START`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "const TAG : TokenType = createToken({\n",
    "  name: \"TAG\",\n",
    "  pattern: /<[^>]+>/,\n",
    "  group: Lexer.SKIPPED\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741751fc",
   "metadata": {},
   "source": [
    "The pattern `/<[^>]+>/` matches:\n",
    "\n",
    "- An opening angle bracket `<`\n",
    "- One or more characters that are not a closing angle bracket `([^>]+)`\n",
    "- A closing angle bracket `>`\n",
    "\n",
    "This catches tags like `<div>`, `</p>`, `<br/>`, `<a href=\"...\">`, etc. The `group: Lexer.SKIPPED` property is important - it tells Chevrotain to recognize these tags but immediately discard them from the token stream. This means they won't appear in our final output, which is exactly what we want when extracting plain text from HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dfbee",
   "metadata": {},
   "source": [
    "### The Definition of the Token `NAMED_ENTITY`\n",
    "\n",
    "<span style=\"font-variant:small-caps;\">Html</span> uses named entities to represent special characters, like `&auml;` for \"√§\" or `&nbsp;` for a non-breaking space. The `NAMED_ENTITY` token recognizes these patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const NAMED_ENTITY : TokenType = createToken({\n",
    "  name: \"NAMED_ENTITY\",\n",
    "  pattern: /&[A-Za-z]+;?/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6e522",
   "metadata": {},
   "source": [
    "The pattern `/&[A-Za-z]+;?/` matches:\n",
    "\n",
    "- An ampersand `&`\n",
    "- One or more letters (`[A-Za-z]+`)\n",
    "- An optional semicolon (`;?`)\n",
    "\n",
    "The semicolon is optional because some HTML documents omit it, though it's technically required by the HTML5 standard. Examples this matches:\n",
    "\n",
    "- `&auml`; ‚Üí √§\n",
    "- `&uuml`; ‚Üí √º\n",
    "- `&nbsp`; ‚Üí non-breaking space\n",
    "\n",
    "Later, in our token processing function, we'll use the decodeHTML function from the entities package to convert these named entities into their corresponding Unicode characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decodeHTML(\"&auml;\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418fb671",
   "metadata": {},
   "source": [
    "### The Definition of the Token `UNICODE` \n",
    "\n",
    "Besides named entities, <span style=\"font-variant:small-caps;\">Html</span> also supports numeric Unicode entities that specify characters by their code point. These come in two forms: decimal (like `&#8555;`) and hexadecimal (though we only handle decimal here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "const UNICODE : TokenType = createToken({\n",
    "  name: \"UNICODE\",\n",
    "  pattern: /&#[0-9]+;?/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef7e26",
   "metadata": {},
   "source": [
    "The pattern /&#[0-9]+;?/ matches:\n",
    "\n",
    "- An ampersand `&`\n",
    "- A hash symbol `#`\n",
    "- One or more digits (`[0-9]+`)\n",
    "- An optional semicolon (`;?`)\n",
    "\n",
    "Examples this matches:\n",
    "\n",
    "- `&#8555;` ‚Üí ‚Ö´ (Roman numeral twelve)\n",
    "- `&#128034;` ‚Üí üê¢ (turtle emoji)\n",
    "- `&#228;` ‚Üí √§ (same as &auml;)\n",
    "\n",
    "Like `NAMED_ENTITY`, this token must come before the `ANY` token in the mode definition. Otherwise, the `&` character would be captured by `ANY`, and the entity would never be recognized. In our token processing function, we'll use String.fromCodePoint() to convert the numeric code into its corresponding Unicode character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ace0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "String.fromCodePoint(8555);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb024ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "String.fromCodePoint(128034);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d03233d",
   "metadata": {},
   "source": [
    "### The Definition of the Token `ANY` \n",
    "\n",
    "The `ANY` token is our \"catch-all\" for regular text content. It matches any sequence of characters that don't start an HTML tag or entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57375f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "const ANY : TokenType = createToken({\n",
    "  name: \"ANY\",\n",
    "  pattern: /[^<&\\r\\n]+/\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8c48b",
   "metadata": {},
   "source": [
    "The pattern `/[^<&\\r\\n]+/` matches one or more characters that are not:\n",
    "\n",
    "- `<` (which would start an HTML tag)\n",
    "- `&` (which would start an HTML entity)\n",
    "- `\\r` or `\\n` (which are handled by LINEBREAK)\n",
    "\n",
    "**Important**: This token must be defined last among the `initial_mode` tokens. Chevrotain tries to match tokens in the order they appear in the mode definition, so more specific patterns (like `TAG`, `NAMED_ENTITY`) must come before this general pattern. Otherwise, `ANY` would greedily consume characters that should be matched by other tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d090ad",
   "metadata": {},
   "source": [
    "### The Definition of the Token `HEAD_END` \n",
    "\n",
    "The `HEAD_END` token marks the end of the HTML header section and triggers a return to normal text extraction mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HEAD_END : TokenType = createToken({\n",
    "  name: \"HEAD_END\",\n",
    "  pattern: /<\\/head>/i,\n",
    "  pop_mode: true\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060466b3",
   "metadata": {},
   "source": [
    "The pattern /<\\/head>/i matches:\n",
    "\n",
    "- An opening angle bracket `<`\n",
    "- A forward slash `\\/` (escaped because `/` has special meaning in regex)\n",
    "- The word \"head\"\n",
    "- A closing angle bracket `>`\n",
    "- The `i` flag makes it case-insensitive\n",
    "\n",
    "The `pop_mode: true` property tells Chevrotain to return to the previous mode (which was `initial_mode` before we pushed to `header_mode`). This token is only active in `header_mode`, not in the `initial mode` - that's why it will only match the closing tag, not cause conflicts with other patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de68e8c",
   "metadata": {},
   "source": [
    "### The Definition of the Token `SCRIPT_END`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c077291a",
   "metadata": {},
   "source": [
    "Similar to `HEAD_END`, the `SCRIPT_END` token marks the end of embedded JavaScript code and returns the lexer to normal mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const SCRIPT_END : TokenType = createToken({\n",
    "  name: \"SCRIPT_END\",\n",
    "  pattern: /<\\/script>/i,\n",
    "  pop_mode: true\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47051f8",
   "metadata": {},
   "source": [
    "The pattern `/<\\/script>/i` matches the closing script tag with case-insensitive matching. Like `HEAD_END`, the `pop_mode: true` property returns the lexer to `initial_mode` after this token is matched.\n",
    "\n",
    "This token is only active in `script_mode`, ensuring that JavaScript code between `<script>` and `</script>` tags is completely ignored and not extracted as text content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348f07a",
   "metadata": {},
   "source": [
    "### The Definition of Content Tokens for Special Modes\n",
    "\n",
    "When the lexer is in `header_mode` or `script_mode`, we need tokens that will consume (and discard) all content until the respective end tag is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HeaderContent : TokenType = createToken({\n",
    "  name: \"HeaderContent\",\n",
    "  pattern: /(.|\\n)+?(?=<\\/head>)/i,\n",
    "  line_breaks: true,\n",
    "  group: Lexer.SKIPPED\n",
    "});\n",
    "\n",
    "const ScriptContent : TokenType = createToken({\n",
    "  name: \"ScriptContent\",\n",
    "  pattern: /(.|\\n)+?(?=<\\/script>)/i,\n",
    "  line_breaks: true,\n",
    "  group: Lexer.SKIPPED\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b6e7e",
   "metadata": {},
   "source": [
    "These patterns use advanced regex features:\n",
    "\n",
    "- `(.|\\n)+?` matches any character (`.`) or newline (`\\n`), one or more times, non-greedy (`+?`)\n",
    "- `(?=<\\/head>)` is a positive lookahead‚Äîit checks that the closing tag follows, but doesn't consume it\n",
    "- `line_breaks: true` is essential because these patterns span multiple lines\n",
    "- `group: Lexer.SKIPPED` ensures this content is discarded, not extracted\n",
    "\n",
    "The non-greedy match (`+?`) combined with the lookahead ensures that these tokens stop just before the end tag, allowing `HEAD_END` or `SCRIPT_END` to match correctly. Without the lookahead, the pattern might consume the end tag itself, preventing the mode switch back to `initial_mode`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8220d1",
   "metadata": {},
   "source": [
    "## Running the Scanner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40a8f97",
   "metadata": {},
   "source": [
    "### Creating the Lexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d36257",
   "metadata": {},
   "source": [
    "Now that all tokens are defined, we can create the actual Chevrotain lexer. The lexer is configured with multiple modes, each containing a specific set of active tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a599f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "const HtmlLexer : Lexer = new Lexer({\n",
    "  defaultMode: \"initial_mode\",\n",
    "  modes: {\n",
    "    initial_mode: [\n",
    "      HEAD_START,\n",
    "      SCRIPT_START,\n",
    "      LINEBREAK,\n",
    "      TAG,\n",
    "      NAMED_ENTITY,\n",
    "      UNICODE,\n",
    "      ANY\n",
    "    ],\n",
    "    header_mode: [\n",
    "      HEAD_END,\n",
    "      HeaderContent\n",
    "    ],\n",
    "    script_mode: [\n",
    "      SCRIPT_END,\n",
    "      ScriptContent\n",
    "    ]\n",
    "  }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e8bd31",
   "metadata": {},
   "source": [
    "The lexer configuration specifies:\n",
    "\n",
    "- `defaultMode`: The mode the lexer starts in (`initial_mode`)\n",
    "- `modes`: An object defining which tokens are active in each mode\n",
    "\n",
    "**Token order matters!** Within each mode, tokens are tried in the order they appear. Specific patterns (like `NAMED_ENTITY`, `UNICODE`) must come before general ones (like `ANY`) to ensure correct matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a70f7",
   "metadata": {},
   "source": [
    "### Processing Tokens\n",
    "\n",
    "After tokenization, we need to process the tokens and reconstruct the plain text. The `processTokens` function iterates through all recognized tokens and builds the output string.\n",
    "\n",
    "Instead of comparing token names as strings (which is prone to typos), we use Chevrotain's `tokenMatcher` utility. This ensures type safety and robustness, even if we rename our tokens later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "function processTokens(tokens: IToken[]): string {\n",
    "  let result : string = \"\";\n",
    "  \n",
    "  for (const token of tokens) {\n",
    "    if (tokenMatcher(token, LINEBREAK)) {\n",
    "      result += \"\\n\";\n",
    "    } \n",
    "    else if (tokenMatcher(token, NAMED_ENTITY)) {\n",
    "      const entityText: string = token.image;\n",
    "      const cleanEntity: string = entityText.replace(/^&|;$/g, \"\");\n",
    "      result += decodeHTML(`&${cleanEntity};`);\n",
    "    } \n",
    "    else if (tokenMatcher(token, UNICODE)) {\n",
    "      const unicodeText: string = token.image;\n",
    "      const cleanNumber: string = unicodeText.replace(/^&#|;$/g, \"\");\n",
    "      result += String.fromCodePoint(parseInt(cleanNumber, 10));\n",
    "    } \n",
    "    else if (tokenMatcher(token, ANY)) {\n",
    "      result += token.image;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return result;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e5a15",
   "metadata": {},
   "source": [
    "Each token type is handled differently:\n",
    "\n",
    "- **`LINEBREAK`**: Outputs a single newline character. Since our lexer pattern already consumed sequences of whitespace and newlines, this effectively condenses them into one.\n",
    "- **`NAMED_ENTITY`**: Extracts the entity name (removing the leading `&` and optional trailing `;`) and converts it to a character using `decodeHTML`.\n",
    "- **`UNICODE`**: Extracts the numeric code (removing `&#` and optional `;`) and converts it to a character using `String.fromCodePoint`.\n",
    "- **`ANY`**: Outputs the matched text exactly as it appeared in the source.\n",
    "\n",
    "Note that tokens like `HEAD_START`, `SCRIPT_START`, `HEAD_END`, and `SCRIPT_END` are not handled here because they serve only as control signals for mode switching and do not produce content. Similarly, the `TAG` token is missing because it was marked as `SKIPPED` in the lexer definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b9d7b",
   "metadata": {},
   "source": [
    "### Tokenizing and Extracting Text\n",
    "\n",
    "Finally, we feed our HTML data into the lexer and extract the plain text. The tokenize method returns a lexingResult object containing:\n",
    "\n",
    "- `tokens`: An array of successfully recognized tokens\n",
    "- `errors`: An array of any lexing errors encountered\n",
    "\n",
    "Error checking is included for robustness, though with our `ANY` token as a catch-all, lexing errors should never occur. The extracted text is then printed to the console, showing the HTML document stripped of all tags and with entities properly converted to Unicode characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3fb84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "const lexingResult: ILexingResult = HtmlLexer.tokenize(data);\n",
    "\n",
    "if (lexingResult.errors.length > 0) {\n",
    "  console.error(\"Lexing errors detected:\");\n",
    "\n",
    "  for (const error of lexingResult.errors) {\n",
    "    const charFromMessage: string | undefined = error.message.match(/->(.)<-/)?.[1];\n",
    "    const illegalChar: string = charFromMessage || data.substr(error.offset, error.length) || \"?\";\n",
    "\n",
    "    console.error(`  - Illegal character '${illegalChar}' at line ${error.line}.`);\n",
    "    console.error(`    This is the ${error.offset}th character.`);\n",
    "  }\n",
    "}\n",
    "\n",
    "const extractedText = processTokens(lexingResult.tokens as IToken[]);\n",
    "console.log(extractedText);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad975ec2",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "The result is clean, readable text extracted from the HTML source. All tags have been removed, HTML entities like `&uuml;` have been converted to their Unicode equivalents (√º), and numeric entities like `&#8555;` have been converted to their characters (‚Ö´)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010dde3",
   "metadata": {},
   "source": [
    "### Inspecting Individual Tokens\n",
    "\n",
    "For debugging or educational purposes, you can inspect each token individually to see how the lexer processed the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0f32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (const tok of lexingResult.tokens as IToken[]) {\n",
    "  console.log({\n",
    "    name: tok.tokenType.name,\n",
    "    image: tok.image,\n",
    "    startLine: tok.startLine,\n",
    "    startColumn: tok.startColumn\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c32cb",
   "metadata": {},
   "source": [
    "Each token object contains:\n",
    "\n",
    "- `tokenType.name`: The type of token (e.g., \"`LINEBREAK`\", \"`ANY`\")\n",
    "\n",
    "- `image`: The actual matched text from the source\n",
    "\n",
    "- `startLine` and `startColumn`: Position information for debugging\n",
    "\n",
    "This allows you to see exactly how Chevrotain broke down the HTML into individual tokens before processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
